{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2\n",
    "from PIL import Image \n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH=224\n",
    "IMG_HEIGHT=224\n",
    "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT)\n",
    "BATCH_SIZE = 25\n",
    "IMG_DIR = pathlib.Path('G:\\Github\\standford-dogs\\cropped')\n",
    "TRAIN_DIR = 'G:/Github/standford-dogs/cropped/train'\n",
    "VAL_DIR = 'G:/Github/standford-dogs/cropped/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifiy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Specify the values for all arguments to data_generator_with_aug.\n",
    "data_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                              horizontal_flip = True,\n",
    "                                              width_shift_range = 0.2,\n",
    "                                              height_shift_range = 0.2\n",
    "                                                )\n",
    "            \n",
    "data_generator_no_aug = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16464 images belonging to 120 classes.\n",
      "Found 4116 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator_with_aug.flow_from_directory(\n",
    "                                        directory=TRAIN_DIR,\n",
    "                                        target_size=IMG_DIM,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "validation_generator = data_generator_no_aug.flow_from_directory(\n",
    "                                        directory=VAL_DIR,\n",
    "                                        target_size=IMG_DIM,batch_size=BATCH_SIZE,\n",
    "                                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool (GlobalMaxPooling2D)   (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "resnet = ResNet50(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT,IMG_WIDTH,3),pooling='max')\n",
    "\n",
    "output = resnet.layers[-1].output\n",
    "output = tf.keras.layers.Flatten()(output)\n",
    "resnet = Model(resnet.input, output)\n",
    "\n",
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Model)              (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 120)               123000    \n",
      "=================================================================\n",
      "Total params: 26,858,488\n",
      "Trainable params: 26,805,368\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "num_classes = 120\n",
    "\n",
    "model = Sequential()\n",
    "model.add(resnet)\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Indicate whether the first layer should be trained/changed or not.\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to use resnet50 as feature extraction, hence adding pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5,\n",
    "                                              restore_best_weights=False\n",
    "                                              )\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                   factor=0.2,\n",
    "                                   patience=3,\n",
    "                                   verbose=1,\n",
    "                                   min_delta=1e-4,min_lr = 1e-5,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 659.0 steps, validate for 165.0 steps\n",
      "Epoch 1/100\n",
      "659/659 [==============================] - 231s 350ms/step - loss: 4.6867 - accuracy: 0.0990 - val_loss: 2.0608 - val_accuracy: 0.4529\n",
      "Epoch 2/100\n",
      "659/659 [==============================] - 219s 333ms/step - loss: 2.5414 - accuracy: 0.3452 - val_loss: 1.1943 - val_accuracy: 0.6426\n",
      "Epoch 3/100\n",
      "659/659 [==============================] - 214s 324ms/step - loss: 1.9552 - accuracy: 0.4668 - val_loss: 1.0789 - val_accuracy: 0.6788\n",
      "Epoch 4/100\n",
      "659/659 [==============================] - 205s 312ms/step - loss: 1.6660 - accuracy: 0.5294 - val_loss: 0.9577 - val_accuracy: 0.7128\n",
      "Epoch 5/100\n",
      "659/659 [==============================] - 205s 310ms/step - loss: 1.5092 - accuracy: 0.5697 - val_loss: 0.9041 - val_accuracy: 0.7204\n",
      "Epoch 6/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 1.3997 - accuracy: 0.5963 - val_loss: 0.9521 - val_accuracy: 0.7072\n",
      "Epoch 7/100\n",
      "659/659 [==============================] - 204s 310ms/step - loss: 1.2910 - accuracy: 0.6195 - val_loss: 0.8407 - val_accuracy: 0.7417\n",
      "Epoch 8/100\n",
      "659/659 [==============================] - 204s 310ms/step - loss: 1.2315 - accuracy: 0.6373 - val_loss: 0.8408 - val_accuracy: 0.7393\n",
      "Epoch 9/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 1.1592 - accuracy: 0.6551 - val_loss: 0.8574 - val_accuracy: 0.7315\n",
      "Epoch 10/100\n",
      "658/659 [============================>.] - ETA: 0s - loss: 1.1102 - accuracy: 0.6666\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 1.1099 - accuracy: 0.6668 - val_loss: 0.8622 - val_accuracy: 0.7318\n",
      "Epoch 11/100\n",
      "659/659 [==============================] - 205s 310ms/step - loss: 0.9402 - accuracy: 0.7133 - val_loss: 0.7996 - val_accuracy: 0.7566\n",
      "Epoch 12/100\n",
      "659/659 [==============================] - 216s 328ms/step - loss: 0.9035 - accuracy: 0.7221 - val_loss: 0.7800 - val_accuracy: 0.7672\n",
      "Epoch 13/100\n",
      "659/659 [==============================] - 219s 332ms/step - loss: 0.8923 - accuracy: 0.7218 - val_loss: 0.7980 - val_accuracy: 0.7583\n",
      "Epoch 14/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 0.8749 - accuracy: 0.7291 - val_loss: 0.7735 - val_accuracy: 0.7646\n",
      "Epoch 15/100\n",
      "659/659 [==============================] - 204s 310ms/step - loss: 0.8631 - accuracy: 0.7345 - val_loss: 0.7622 - val_accuracy: 0.7682\n",
      "Epoch 16/100\n",
      "659/659 [==============================] - 216s 327ms/step - loss: 0.8569 - accuracy: 0.7351 - val_loss: 0.7610 - val_accuracy: 0.7685\n",
      "Epoch 17/100\n",
      "659/659 [==============================] - 228s 345ms/step - loss: 0.8276 - accuracy: 0.7422 - val_loss: 0.7522 - val_accuracy: 0.7743\n",
      "Epoch 18/100\n",
      "659/659 [==============================] - 208s 315ms/step - loss: 0.8347 - accuracy: 0.7428 - val_loss: 0.7612 - val_accuracy: 0.7726\n",
      "Epoch 19/100\n",
      "659/659 [==============================] - 208s 315ms/step - loss: 0.8127 - accuracy: 0.7473 - val_loss: 0.7593 - val_accuracy: 0.7694\n",
      "Epoch 20/100\n",
      "658/659 [============================>.] - ETA: 0s - loss: 0.7934 - accuracy: 0.7535\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "659/659 [==============================] - 207s 314ms/step - loss: 0.7936 - accuracy: 0.7535 - val_loss: 0.7595 - val_accuracy: 0.7675\n",
      "Epoch 21/100\n",
      "659/659 [==============================] - 207s 314ms/step - loss: 0.7842 - accuracy: 0.7565 - val_loss: 0.7603 - val_accuracy: 0.7736\n",
      "Epoch 22/100\n",
      "659/659 [==============================] - 207s 314ms/step - loss: 0.7657 - accuracy: 0.7640 - val_loss: 0.7554 - val_accuracy: 0.7711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15d8915ae80>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,steps_per_epoch=np.ceil(float(16464) / float(BATCH_SIZE)),\n",
    "                        epochs = 100,callbacks=[early_stop,reduce_lr],\n",
    "                          validation_steps=np.ceil(float(4116) / float(BATCH_SIZE)),\n",
    "                        validation_data = validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagnostic_plot(model,name):\n",
    "    training_loss = model.history.history[name]\n",
    "    test_loss = model.history.history[f'val_{name}']\n",
    "\n",
    "    # Create count of the number of epochs\n",
    "    epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    # Visualize loss history\n",
    "    plt.plot(epoch_count, training_loss, 'r--')\n",
    "    plt.plot(epoch_count, test_loss, 'b-')\n",
    "    plt.legend([f'Training {name}', f'Val {name}'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_diagnostic_plot(model,'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_diagnostic_plot(model,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Zhiqing\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: G:/Github/Dogs_breed_classification/resnet50_2/assets\n"
     ]
    }
   ],
   "source": [
    "save_path = 'G:/Github/Dogs_breed_classification/resnet50_2/'\n",
    "tf.keras.models.save_model(model,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
