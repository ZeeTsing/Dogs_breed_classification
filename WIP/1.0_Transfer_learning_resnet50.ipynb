{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2\n",
    "from PIL import Image \n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH=224\n",
    "IMG_HEIGHT=224\n",
    "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT)\n",
    "BATCH_SIZE = 25\n",
    "IMG_DIR = pathlib.Path('G:\\Github\\standford-dogs\\cropped')\n",
    "TRAIN_DIR = 'G:/Github/standford-dogs/cropped/train'\n",
    "VAL_DIR = 'G:/Github/standford-dogs/cropped/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifiy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Specify the values for all arguments to data_generator_with_aug.\n",
    "data_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                              horizontal_flip = True,\n",
    "                                              width_shift_range = 0.2,\n",
    "                                              height_shift_range = 0.2,\n",
    "                                             zoom_range = 0.4\n",
    "                                                )\n",
    "            \n",
    "data_generator_no_aug = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16464 images belonging to 120 classes.\n",
      "Found 4116 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator_with_aug.flow_from_directory(\n",
    "                                        directory=TRAIN_DIR,\n",
    "                                        target_size=IMG_DIM,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "validation_generator = data_generator_no_aug.flow_from_directory(\n",
    "                                        directory=VAL_DIR,\n",
    "                                        target_size=IMG_DIM,batch_size=BATCH_SIZE,\n",
    "                                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool (GlobalMaxPooling2D)   (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "resnet = ResNet50(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT,IMG_WIDTH,3),pooling='max')\n",
    "\n",
    "output = resnet.layers[-1].output\n",
    "output = tf.keras.layers.Flatten()(output)\n",
    "resnet = Model(resnet.input, output)\n",
    "\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Model)              (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               123000    \n",
      "=================================================================\n",
      "Total params: 26,858,488\n",
      "Trainable params: 3,270,776\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "num_classes = 120\n",
    "\n",
    "model = Sequential()\n",
    "model.add(resnet)\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to use resnet50 as feature extraction, hence adding pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8,\n",
    "                                              restore_best_weights=False\n",
    "                                              )\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                   factor=0.2,\n",
    "                                   patience=4,\n",
    "                                   verbose=1,\n",
    "                                   min_delta=1e-3,min_lr = 1e-6,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = adam, \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics=['accuracy',tfa.metrics.F1Score(num_classes=num_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 659.0 steps, validate for 165.0 steps\n",
      "Epoch 1/100\n",
      "659/659 [==============================] - 323s 489ms/step - loss: 4.8365 - accuracy: 0.0754 - f1_score: 0.0690 - val_loss: 2.2698 - val_accuracy: 0.4332 - val_f1_score: 0.3965\n",
      "Epoch 2/100\n",
      "659/659 [==============================] - 232s 351ms/step - loss: 2.8647 - accuracy: 0.2892 - f1_score: 0.2763 - val_loss: 1.3149 - val_accuracy: 0.6084 - val_f1_score: 0.5879\n",
      "Epoch 3/100\n",
      "659/659 [==============================] - 233s 354ms/step - loss: 2.2499 - accuracy: 0.4028 - f1_score: 0.3944 - val_loss: 1.0934 - val_accuracy: 0.6664 - val_f1_score: 0.6549\n",
      "Epoch 4/100\n",
      "659/659 [==============================] - 236s 358ms/step - loss: 1.9823 - accuracy: 0.4569 - f1_score: 0.4483 - val_loss: 0.9735 - val_accuracy: 0.7087 - val_f1_score: 0.6931\n",
      "Epoch 5/100\n",
      "659/659 [==============================] - 242s 368ms/step - loss: 1.8096 - accuracy: 0.5014 - f1_score: 0.4936 - val_loss: 0.9028 - val_accuracy: 0.7252 - val_f1_score: 0.7097\n",
      "Epoch 6/100\n",
      "659/659 [==============================] - 233s 353ms/step - loss: 1.6909 - accuracy: 0.5245 - f1_score: 0.5172 - val_loss: 0.8954 - val_accuracy: 0.7235 - val_f1_score: 0.7104\n",
      "Epoch 7/100\n",
      "659/659 [==============================] - 224s 340ms/step - loss: 1.6145 - accuracy: 0.5440 - f1_score: 0.5371 - val_loss: 0.9398 - val_accuracy: 0.7087 - val_f1_score: 0.6947\n",
      "Epoch 8/100\n",
      "659/659 [==============================] - 224s 339ms/step - loss: 1.5374 - accuracy: 0.5634 - f1_score: 0.5572 - val_loss: 0.8635 - val_accuracy: 0.7310 - val_f1_score: 0.7170\n",
      "Epoch 9/100\n",
      "659/659 [==============================] - 220s 334ms/step - loss: 1.4643 - accuracy: 0.5802 - f1_score: 0.5732 - val_loss: 0.8506 - val_accuracy: 0.7400 - val_f1_score: 0.7278\n",
      "Epoch 10/100\n",
      "659/659 [==============================] - 218s 331ms/step - loss: 1.4373 - accuracy: 0.5907 - f1_score: 0.5848 - val_loss: 0.8543 - val_accuracy: 0.7415 - val_f1_score: 0.7331\n",
      "Epoch 11/100\n",
      "659/659 [==============================] - 219s 332ms/step - loss: 1.3808 - accuracy: 0.6021 - f1_score: 0.5960 - val_loss: 0.7951 - val_accuracy: 0.7524 - val_f1_score: 0.7437\n",
      "Epoch 12/100\n",
      "659/659 [==============================] - 219s 333ms/step - loss: 1.3506 - accuracy: 0.6095 - f1_score: 0.6039 - val_loss: 0.7687 - val_accuracy: 0.7634 - val_f1_score: 0.7567\n",
      "Epoch 13/100\n",
      "659/659 [==============================] - 219s 332ms/step - loss: 1.3215 - accuracy: 0.6180 - f1_score: 0.6118 - val_loss: 0.7627 - val_accuracy: 0.7621 - val_f1_score: 0.7549\n",
      "Epoch 14/100\n",
      "659/659 [==============================] - 231s 350ms/step - loss: 1.2885 - accuracy: 0.6271 - f1_score: 0.6208 - val_loss: 0.7671 - val_accuracy: 0.7709 - val_f1_score: 0.7636\n",
      "Epoch 15/100\n",
      "659/659 [==============================] - 290s 440ms/step - loss: 1.2550 - accuracy: 0.6384 - f1_score: 0.6328 - val_loss: 0.7701 - val_accuracy: 0.7602 - val_f1_score: 0.7531\n",
      "Epoch 16/100\n",
      "659/659 [==============================] - 262s 398ms/step - loss: 1.2190 - accuracy: 0.6440 - f1_score: 0.6386 - val_loss: 0.7623 - val_accuracy: 0.7634 - val_f1_score: 0.7542\n",
      "Epoch 17/100\n",
      "659/659 [==============================] - 226s 342ms/step - loss: 1.1888 - accuracy: 0.6474 - f1_score: 0.6425 - val_loss: 0.7547 - val_accuracy: 0.7653 - val_f1_score: 0.7598\n",
      "Epoch 18/100\n",
      "659/659 [==============================] - 230s 348ms/step - loss: 1.1849 - accuracy: 0.6519 - f1_score: 0.6469 - val_loss: 0.7356 - val_accuracy: 0.7741 - val_f1_score: 0.7655\n",
      "Epoch 19/100\n",
      "659/659 [==============================] - 230s 349ms/step - loss: 1.1626 - accuracy: 0.6581 - f1_score: 0.6527 - val_loss: 0.7344 - val_accuracy: 0.7767 - val_f1_score: 0.7694\n",
      "Epoch 20/100\n",
      "659/659 [==============================] - 223s 338ms/step - loss: 1.1285 - accuracy: 0.6664 - f1_score: 0.6611 - val_loss: 0.7176 - val_accuracy: 0.7794 - val_f1_score: 0.7699\n",
      "Epoch 21/100\n",
      "659/659 [==============================] - 223s 339ms/step - loss: 1.1194 - accuracy: 0.6686 - f1_score: 0.6633 - val_loss: 0.7167 - val_accuracy: 0.7806 - val_f1_score: 0.7725\n",
      "Epoch 22/100\n",
      "659/659 [==============================] - 218s 331ms/step - loss: 1.0841 - accuracy: 0.6759 - f1_score: 0.6707 - val_loss: 0.7490 - val_accuracy: 0.7728 - val_f1_score: 0.7639\n",
      "Epoch 23/100\n",
      "659/659 [==============================] - 225s 341ms/step - loss: 1.0867 - accuracy: 0.6748 - f1_score: 0.6699 - val_loss: 0.7476 - val_accuracy: 0.7690 - val_f1_score: 0.7581\n",
      "Epoch 24/100\n",
      "659/659 [==============================] - 225s 342ms/step - loss: 1.0785 - accuracy: 0.6763 - f1_score: 0.6714 - val_loss: 0.7265 - val_accuracy: 0.7782 - val_f1_score: 0.7685\n",
      "Epoch 25/100\n",
      "659/659 [==============================] - 225s 341ms/step - loss: 1.0567 - accuracy: 0.6832 - f1_score: 0.6786 - val_loss: 0.7052 - val_accuracy: 0.7770 - val_f1_score: 0.7698\n",
      "Epoch 26/100\n",
      "659/659 [==============================] - 224s 340ms/step - loss: 1.0346 - accuracy: 0.6860 - f1_score: 0.6815 - val_loss: 0.7045 - val_accuracy: 0.7809 - val_f1_score: 0.7728\n",
      "Epoch 27/100\n",
      "659/659 [==============================] - 225s 341ms/step - loss: 1.0222 - accuracy: 0.6928 - f1_score: 0.6881 - val_loss: 0.7301 - val_accuracy: 0.7816 - val_f1_score: 0.7744\n",
      "Epoch 28/100\n",
      "659/659 [==============================] - 224s 341ms/step - loss: 1.0123 - accuracy: 0.6958 - f1_score: 0.6916 - val_loss: 0.7235 - val_accuracy: 0.7787 - val_f1_score: 0.7704\n",
      "Epoch 29/100\n",
      "659/659 [==============================] - 225s 341ms/step - loss: 0.9959 - accuracy: 0.7002 - f1_score: 0.6955 - val_loss: 0.6995 - val_accuracy: 0.7838 - val_f1_score: 0.7749\n",
      "Epoch 30/100\n",
      "659/659 [==============================] - 224s 340ms/step - loss: 0.9840 - accuracy: 0.7016 - f1_score: 0.6980 - val_loss: 0.7155 - val_accuracy: 0.7840 - val_f1_score: 0.7805\n",
      "Epoch 31/100\n",
      "659/659 [==============================] - 225s 342ms/step - loss: 0.9987 - accuracy: 0.7019 - f1_score: 0.6975 - val_loss: 0.7139 - val_accuracy: 0.7826 - val_f1_score: 0.7725\n",
      "Epoch 32/100\n",
      "659/659 [==============================] - 219s 333ms/step - loss: 0.9687 - accuracy: 0.7066 - f1_score: 0.7023 - val_loss: 0.7426 - val_accuracy: 0.7789 - val_f1_score: 0.7706\n",
      "Epoch 33/100\n",
      "658/659 [============================>.] - ETA: 0s - loss: 0.9394 - accuracy: 0.7128 - f1_score: 0.7086\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "659/659 [==============================] - 218s 330ms/step - loss: 0.9393 - accuracy: 0.7128 - f1_score: 0.7086 - val_loss: 0.7141 - val_accuracy: 0.7765 - val_f1_score: 0.7668\n",
      "Epoch 34/100\n",
      "659/659 [==============================] - 215s 326ms/step - loss: 0.8625 - accuracy: 0.7393 - f1_score: 0.7355 - val_loss: 0.6760 - val_accuracy: 0.7942 - val_f1_score: 0.7883\n",
      "Epoch 35/100\n",
      "659/659 [==============================] - 215s 327ms/step - loss: 0.8160 - accuracy: 0.7491 - f1_score: 0.7457 - val_loss: 0.6703 - val_accuracy: 0.7942 - val_f1_score: 0.7878\n",
      "Epoch 36/100\n",
      "659/659 [==============================] - 215s 327ms/step - loss: 0.8190 - accuracy: 0.7476 - f1_score: 0.7433 - val_loss: 0.6770 - val_accuracy: 0.7940 - val_f1_score: 0.7871\n",
      "Epoch 37/100\n",
      "659/659 [==============================] - 216s 327ms/step - loss: 0.8118 - accuracy: 0.7532 - f1_score: 0.7488 - val_loss: 0.6835 - val_accuracy: 0.7903 - val_f1_score: 0.7843\n",
      "Epoch 38/100\n",
      "659/659 [==============================] - 215s 327ms/step - loss: 0.8155 - accuracy: 0.7497 - f1_score: 0.7459 - val_loss: 0.6659 - val_accuracy: 0.7952 - val_f1_score: 0.7898\n",
      "Epoch 39/100\n",
      "659/659 [==============================] - 215s 326ms/step - loss: 0.7970 - accuracy: 0.7551 - f1_score: 0.7514 - val_loss: 0.6650 - val_accuracy: 0.7964 - val_f1_score: 0.7905\n",
      "Epoch 40/100\n",
      "659/659 [==============================] - 215s 326ms/step - loss: 0.8085 - accuracy: 0.7515 - f1_score: 0.7480 - val_loss: 0.6761 - val_accuracy: 0.7937 - val_f1_score: 0.7879\n",
      "Epoch 41/100\n",
      "659/659 [==============================] - 215s 327ms/step - loss: 0.7859 - accuracy: 0.7560 - f1_score: 0.7529 - val_loss: 0.6678 - val_accuracy: 0.7969 - val_f1_score: 0.7911\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659/659 [==============================] - 216s 327ms/step - loss: 0.7841 - accuracy: 0.7561 - f1_score: 0.7524 - val_loss: 0.6748 - val_accuracy: 0.7964 - val_f1_score: 0.7901\n",
      "Epoch 43/100\n",
      "658/659 [============================>.] - ETA: 0s - loss: 0.7861 - accuracy: 0.7550 - f1_score: 0.7520\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "659/659 [==============================] - 215s 327ms/step - loss: 0.7859 - accuracy: 0.7550 - f1_score: 0.7520 - val_loss: 0.6739 - val_accuracy: 0.7947 - val_f1_score: 0.7894\n",
      "Epoch 44/100\n",
      "659/659 [==============================] - 215s 327ms/step - loss: 0.7677 - accuracy: 0.7635 - f1_score: 0.7595 - val_loss: 0.6732 - val_accuracy: 0.7930 - val_f1_score: 0.7877\n",
      "Epoch 45/100\n",
      "659/659 [==============================] - 215s 326ms/step - loss: 0.7678 - accuracy: 0.7653 - f1_score: 0.7617 - val_loss: 0.6695 - val_accuracy: 0.7918 - val_f1_score: 0.7861\n",
      "Epoch 46/100\n",
      "659/659 [==============================] - 216s 327ms/step - loss: 0.7584 - accuracy: 0.7631 - f1_score: 0.7593 - val_loss: 0.6680 - val_accuracy: 0.7920 - val_f1_score: 0.7862\n",
      "Epoch 47/100\n",
      "659/659 [==============================] - 216s 328ms/step - loss: 0.7617 - accuracy: 0.7620 - f1_score: 0.7584 - val_loss: 0.6640 - val_accuracy: 0.7945 - val_f1_score: 0.7887\n",
      "Epoch 48/100\n",
      "659/659 [==============================] - 216s 327ms/step - loss: 0.7453 - accuracy: 0.7703 - f1_score: 0.7669 - val_loss: 0.6638 - val_accuracy: 0.7942 - val_f1_score: 0.7885\n",
      "Epoch 49/100\n",
      "659/659 [==============================] - 215s 326ms/step - loss: 0.7572 - accuracy: 0.7676 - f1_score: 0.7644 - val_loss: 0.6640 - val_accuracy: 0.7928 - val_f1_score: 0.7869\n",
      "Epoch 50/100\n",
      "659/659 [==============================] - 215s 327ms/step - loss: 0.7486 - accuracy: 0.7697 - f1_score: 0.7662 - val_loss: 0.6620 - val_accuracy: 0.7942 - val_f1_score: 0.7878\n",
      "Epoch 51/100\n",
      "659/659 [==============================] - 215s 326ms/step - loss: 0.7534 - accuracy: 0.7731 - f1_score: 0.7705 - val_loss: 0.6675 - val_accuracy: 0.7935 - val_f1_score: 0.7879\n",
      "Epoch 52/100\n",
      "659/659 [==============================] - 215s 326ms/step - loss: 0.7383 - accuracy: 0.7717 - f1_score: 0.7681 - val_loss: 0.6628 - val_accuracy: 0.7940 - val_f1_score: 0.7886\n",
      "Epoch 53/100\n",
      "659/659 [==============================] - 215s 326ms/step - loss: 0.7516 - accuracy: 0.7691 - f1_score: 0.7656 - val_loss: 0.6650 - val_accuracy: 0.7930 - val_f1_score: 0.7872\n",
      "Epoch 54/100\n",
      "658/659 [============================>.] - ETA: 0s - loss: 0.7408 - accuracy: 0.7718 - f1_score: 0.7685\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "659/659 [==============================] - 215s 327ms/step - loss: 0.7407 - accuracy: 0.7718 - f1_score: 0.7685 - val_loss: 0.6633 - val_accuracy: 0.7942 - val_f1_score: 0.7889\n",
      "Epoch 55/100\n",
      "659/659 [==============================] - 220s 334ms/step - loss: 0.7332 - accuracy: 0.7710 - f1_score: 0.7675 - val_loss: 0.6625 - val_accuracy: 0.7945 - val_f1_score: 0.7893\n",
      "Epoch 56/100\n",
      "659/659 [==============================] - 219s 332ms/step - loss: 0.7448 - accuracy: 0.7683 - f1_score: 0.7648 - val_loss: 0.6625 - val_accuracy: 0.7935 - val_f1_score: 0.7882\n",
      "Epoch 57/100\n",
      "659/659 [==============================] - 219s 332ms/step - loss: 0.7509 - accuracy: 0.7652 - f1_score: 0.7622 - val_loss: 0.6616 - val_accuracy: 0.7949 - val_f1_score: 0.7894\n",
      "Epoch 58/100\n",
      "659/659 [==============================] - 218s 330ms/step - loss: 0.7433 - accuracy: 0.7684 - f1_score: 0.7653 - val_loss: 0.6619 - val_accuracy: 0.7945 - val_f1_score: 0.7889\n",
      "Epoch 59/100\n",
      "659/659 [==============================] - 215s 327ms/step - loss: 0.7356 - accuracy: 0.7730 - f1_score: 0.7694 - val_loss: 0.6627 - val_accuracy: 0.7942 - val_f1_score: 0.7888\n",
      "Epoch 60/100\n",
      "659/659 [==============================] - 215s 326ms/step - loss: 0.7389 - accuracy: 0.7699 - f1_score: 0.7662 - val_loss: 0.6620 - val_accuracy: 0.7959 - val_f1_score: 0.7906\n",
      "Epoch 61/100\n",
      "659/659 [==============================] - 215s 326ms/step - loss: 0.7406 - accuracy: 0.7686 - f1_score: 0.7651 - val_loss: 0.6639 - val_accuracy: 0.7949 - val_f1_score: 0.7898\n",
      "Epoch 62/100\n",
      "659/659 [==============================] - 215s 326ms/step - loss: 0.7413 - accuracy: 0.7697 - f1_score: 0.7665 - val_loss: 0.6627 - val_accuracy: 0.7957 - val_f1_score: 0.7906\n",
      "Epoch 63/100\n",
      "659/659 [==============================] - 215s 326ms/step - loss: 0.7423 - accuracy: 0.7688 - f1_score: 0.7653 - val_loss: 0.6639 - val_accuracy: 0.7937 - val_f1_score: 0.7886\n",
      "Epoch 64/100\n",
      "659/659 [==============================] - 215s 326ms/step - loss: 0.7338 - accuracy: 0.7689 - f1_score: 0.7659 - val_loss: 0.6625 - val_accuracy: 0.7937 - val_f1_score: 0.7886\n",
      "Epoch 65/100\n",
      "659/659 [==============================] - 215s 326ms/step - loss: 0.7349 - accuracy: 0.7739 - f1_score: 0.7707 - val_loss: 0.6624 - val_accuracy: 0.7947 - val_f1_score: 0.7894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22a6fca3668>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,steps_per_epoch=np.ceil(float(16464) / float(BATCH_SIZE)),\n",
    "                        epochs = 100,callbacks=[early_stop,reduce_lr],\n",
    "                          validation_steps=np.ceil(float(4116) / float(BATCH_SIZE)),\n",
    "                        validation_data = validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagnostic_plot(model,name):\n",
    "    training_loss = model.history.history[name]\n",
    "    test_loss = model.history.history[f'val_{name}']\n",
    "\n",
    "    # Create count of the number of epochs\n",
    "    epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    # Visualize loss history\n",
    "    plt.plot(epoch_count, training_loss, 'r--')\n",
    "    plt.plot(epoch_count, test_loss, 'b-')\n",
    "    plt.legend([f'Training {name}', f'Val {name}'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_diagnostic_plot(model,'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3deXxU9dX48c8hhCD7jggoUUGESgAjUqAVpCquQEWFUhVRURC09WcV12qtz6M8WreqFC1a0Ba1CFLFBRTFulSCgshOESWsgSBhC2Q5vz/OTDIJE5hAJpPJnPfrNa+Zu8ydM2G4597vKqqKc865xFUj1gE455yLLU8EzjmX4DwROOdcgvNE4JxzCc4TgXPOJbiasQ6gvJo1a6bt2rWLdRjOORdXFi5cuE1Vm4fbFneJoF27dmRkZMQ6DOeciysi8n1Z27xoyDnnEpwnAuecS3CeCJxzLsF5InDOuQQX1UQgIgNEZKWIrBGR8WG2NxSRf4nIYhFZKiLXRDMe55xzB4taIhCRJOAZ4HygEzBMRDqV2u0mYJmqpgF9gcdEpFa0YnLOOXewaN4R9ADWqOpaVT0ATAMGltpHgfoiIkA9IBvIj2JMzjnnSolmP4LWwPqQ5UzgzFL7/BmYBWwE6gNXqGph6QOJyChgFMDxxx8flWCdq+p27YLt22HHDsjOtkeNGtChA7RvD7VrF+9bWAjr1sHixbBsmS3Xrg0pKfaoUwdatoTjjoNWraBJExCJ2VeLa/n5sHUrbNpkrxs0KH7Uq2d/+717Yc8ee96/3/72jRtXnb95NBNBuK9YevKD84BFwNnAScAcEflEVXNKvEl1EjAJID093SdQcHFh3jx44AE4cKDkehFISoKaNYufTzgBevSwx6mn2vrcXPj3v+Hdd+G99+Dbb8v+LBFo1w5OOQVycmDJEksckapVC4491pJC6KNFC0sSjRsXP4tAQYGd9PLz7eT23XewZg3897/2nJVl3yH4/WrWtJNiixbQvLk9N21qJ8etW23/rVvhxx8tYdWta486dSy2/fuLH7m5kJxsJ9qGDe25fn2LI5ggs7PtWMEY8/MtZpHik3TwvXl5JWPYts3+JqGJMyWl+HsEv1Nenp38t261k31Z/y5lTflSpw60aQNt29rfo0ap8pncXPu33LnTnnNyYPRouOeeyP9dIxXNRJAJtA1ZboNd+Ye6BnhYbXacNSLyHdAR+DKKcTkXdR99BBdeaP/BO3Qoua2wsPhEmptrieLzz+Evf7HtdetaMli2zE5utWrBz34GQ4cWX703bWrPBw7AypWwYoU9r1xp77/qKkhLgy5d4Cc/OfhkumcPbN5sJ7LSjzVr4JNP7O6jvFq1gpNOgs6d7XuGnohzcuDLL+2EmxNyqVerVnFyaNQI9u2zk3HwCvrAATsRh56Y8/KKT445OcUn4kaN7O/SpImd6GvVKnnyLiiwBJmdbXdMO3daUgl+/qmnQrNmdlIOJp3g3yw0+RUU2DFPP71k4qxVq2RcOTm2XzCp1a1r+2zeDOvXQ2amPX8Z5oxXq5Z9h0aN7EKhQQP7u0ZDNBPBAqC9iKQCG4ChwK9K7fMD0B/4RERaAqcAa6MYk3NR9+9/w0UXQWqq3RW0aHH49xQWwurVsGCBnRS+/RauvRbOOw/69rUTSFm6dYssruRkuyoPat/+0Pvv31/yCjs724qlVEueXFNS7LueeGLJ4x9Kbq4dr25dO8EdTRGJqiWNY46xmFz5STSnqhSRC4AngCRgsqo+JCI3AqjqRBE5DngJaIUVJT2sqi8f6pjp6enqYw3FF1W7ikpOjs7xCwrsymr37uKryD177CTTqdPBJ+Iff4T334e33rIr9z17iq/y8vPtpNSsWfFVYvPmdqI74wx7HHts2bF8/jmcey60bm3HPtS+zlUmEVmoqulht8XbnMWeCKqeHTuKiyZWrIBVq2DLluIryOxsO8Fecgn8v/8HffpEdgWoCnPm2Ik7eLvfpIkVESxaBJ99Zife//zn0OXhzZrZLXXHjhbjJ5/YSb9JEzjnHDvRh5bZFxZa0URouXFmpr0HrEy3Rw8rcjn55OLH2rV2vBYt4OOPrSLWuarCE4GrEHv2WFFH6El/5Uo7WQYlJ9tJ8bjjik/cjRtbMcOUKVbunJ5uCWHIEDv5hvPBB3DnnVZUUpYaNawM/Kc/teKRhg2Ly2Hr1rUEsnSpPZYtg+XL7SR+0UVWft+zZ+RFCXv2wNdfFxfdfPmlVZCW/u+TmmpJoG3b8MdxLlY8ESSw77+3x89+duTlsHv3wrPPwoQJxSf95s3tCvuUU+wRfJ2aWvbJfe9eSwZ/+pOVh7dsaXH16lV8Ml+yxBLA3Ll2Mn3gAbv6Di2n3r3brvDPOMNai8RKbq4lg9CWMjfcAN7COYyNG63Ws06dw+87b55VtHz1lT02b4azzrLyPID77rMa5PbtrSa+Qwe7DROxWuTp0+0K5fvvrQKjXj2raLnwQnv/F1/Y1UqzZuX/HosXw2uv2ZXK99/bD/+00+Dhh+277dlT3MQonMJCqw2vXfvwVyF799rfIikJBgwof6ylHCoRoKpx9Tj99NPVHd66darXX69as6YqqPbrp7p8efmOsWeP6mOPqbZoYcc491zVOXNUt28/utgKClTffFN16FDVE06wY4NqrVr23KyZ6uOPq+7bd3Sf46qAZctUr7xSNSlJdds2Wzdxouqll6reeafqTTepXnih6tlnF7/noovsh9Chg/1Ifvc7+yEGnXWWanJy8Q8HVAcPtm0FBarHHKMqonrccfbjrVPHjqGqmp1d/J4mTVR/+lPV665T/eijknEfOKC6ZInqyy+r3n676g8/2Ponn7Tv0quX6tVXq555pmqrVva5qvZdQbVBA9XUVNXTT1c9//zi4557bvHn16lj8fXvX7z9179W7dRJ9dRTVVNSbL++fY/2X0FVVYEMLeO8GncT07hin39uZeOh5ec7d8L//i9MnmwXSDfcYBdMv/+9FaPccQfcdZe1sAD7RW7YYFfi69ZZU7Zgs7YlS6wo5xe/gPvvh969KybuGjWsvuCSS2x50yb7Lp9/bt/hppusJYmLIVX49FPIyLCr+U2brKPCgw/a9vvusyvV1FRr29i4sd3itWxp2xcuhP/5H5gxw35st9xidwRgP9olS2DmTPuHbtfOmhyp2o/2mWfglVfK/hF89JFVOv3wg1VIrV5dXCFTo4ZdtbdpU/wjD34fsHWzZ5cs35wxA8480+46vv3WfvA7dhR3AKlVy9a1bQsjRtgjNLZg3ACXX253G9u32yM729r6Bo0cCWefbbeTu3bZ7W3o9hNOsDsGEWsydsEFdtscbWVliKr68DsC1fXrVQcOLHlBFPpITlYdPbr4IkZVdfNmu9gA1RNPVB03zi40mjQp+d6aNe0qvU8f23/+/Jh9TRdLl11W8latXTvVa68t3v6Tn9hVd+iPZ+hQ21ZYqFqvnmrDhqp3362alRX+M/Lzo/89IlFYWBzL8uWq11xjdwEvv2x3BQcOxDa+CsIh7gi8jiCOFBRYWf1dd9nr3//ertJDy88PHIBhw+zCIpwPP4SxY61487TT7C4h2PHopJPsgs7bYscJVfshlFUeDdaj6YsvrOy6sBC6drV/6F277BasUaPix8KFduWbnGyVObt2wRVX2BVruAqm/fvth/TDD1Yz36qV/SBV4emn4eqrrQbfVQleWVwNLF4Mo0ZZa5XzzoPnnrO78iMRvIQr3aXdVQGhxQzr19uJvGPH4uwc3K5qGXzFCsviwU4OvXtbrf2GDXDppVa0E2z3CnYlMXq0VcKefvrBnz91Kvz619H/nq7SHSoReB1BFbd3r5XP/+lPVn7+97/bUANH0xNTpOoMdpVwliyx8u1u3ez2bcMGu+L+6it44w0rr547107mf/2rNZuqU8eu5Fu2tCvwjAz7Bxw1yq7GFy60H8bEiXY7+Pe/27716lkTrLPOsmZeNWoUl6V36GB1ADt22NX8jz9aK5pf/jK2fx8XE54IqrD33rOLt+++s+EGJkywZODi0MaNcO+98OKL8OSTlghWr7ZeaUG1a9vtXrCScsQIK8bJyLCT/ddfQ//+VplYp46V8QUFx6gIDrpTs6YllLLUq2ftdp3DE0GVsX+/tUMP9mT929/gH/+wC8OPP4af/zzWEbojsncvPPYYPPKItXG/7Ta7agcbf2LyZPtHP+kkayseOqhQu3b2uPLKw39OjRr2Y3HuCHgiiKHsbLvKf+GFg0d6rFXLioTGj7f+KS5O3XqrDSs6ZIh1OjrppOJtTZvCNT47q4s9TwQxkJMDjz9u5f67dlmdXlpayUHOTj7ZByyrFsaPt8rXPn1iHYlzZfJEUIlU4amnrE/O9u1WL/fAAyWLiV01MXOmDWsQLN5xrgrzBoSV6Lnn4De/ge7drf5v+nRPAtXSokVWFHTffbGOxLmI+B3BEXjnHWuVV6dOydmJzjjDxqIP54svLAlceCHMmuVt+KutvDwbRqBZM6vkcS4OeCIop+nTrdFHaqrV9S1fbr11f/zRtt9xhw2xEnqiz8qCyy6z4U+mTvUkUK09+qg185w+3dv6urjhiaAcpkyxRh49e9q4VaG95/futQYijzxiQxJPmWJ3DAUFlji2bbOJVBo3jl38LsqWL7e7gCFDvGOWiyueCCL03HMwZoz153nzzYPnkK1Tx/bp0MGaiq9fb/s99ZQNXT55cuRzy7o4Vb++JYAnnoh1JM6ViyeCCDz6KPzud3DxxTYnRe3a4fcTsbuCE0+E4cNtVIAtW+C667y5eLW0bRu8/roNmTxpkk2Q/I9/xDoq58otqqXVIjJARFaKyBoRGR9m++9EZFHg8a2IFIhIlSpYXbrUksBll1mxb1lJINSgQTB/vtUFnHGGDcToqolgJ5DzzrMWAmPGWAVR6HydzsWZqI0+KiJJwCrgHCATWAAMU9VlZex/MfBbVT37UMet7NFHx461nr+ZmeWf2W7fPksG3jO4CsvLs04deXnFEw1PmWIn/Lw8GyAuL8/mxhw40IZzbtLEbvsuucRu/U47zUfxc1VerEYf7QGsUdW1gSCmAQOBsIkAGAZUqfvq3bvtnHD55Uc2vWnoBEmuCvn4Y5v/9qOPbFzv/Hzo18+af4H1+FuzpuR7zjvPEkHdunZV0Lx5pYftXLREMxG0BtaHLGcCZ4bbUUTqAAOAsWVsHwWMAji+EmcG//vfbQiI0aMr7SNdRdq+3YZ9XrLERv/83/+19Q8/DHPmWLndrbdaz9/QMYA++8yek5NtFM/kZBv8KciTgKtmopkIwt0rl1UOdTHwqapmh9uoqpOASWBFQxUT3qGpWiugtDRrLuriyIwZNn3bkiXF64IdvFJS7B+2aVNr5ROOn+hdgolmZXEm0DZkuQ2wsYx9h1LFioW++MJGChg92ot/q7zcXLvCD1bY7t1rtfqPPALvvmuTv2zdWlxZ065d2UnAuQQUzcrimlhlcX9gA1ZZ/CtVXVpqv4bAd0BbVd1zuONWVmXxVVfZuGEbN9ocHq4Kyc62k/yyZdaJa+1au4V77DEr6gmd7tE5B8SoslhV80VkLPAekARMVtWlInJjYPvEwK6DgfcjSQKVZft26y9w7bWeBKqMjAxryXP22VZm/+ST0L69zbv7619bp40BA2xfTwLOlUtUO5Sp6mxgdql1E0stvwS8FM04yuvFF23GMK8kjqLMTKuUrV8fGjUqfhx7rJ3Iv/rKrvY3bIBXX7XlM8+0Mrv69a0ZZ3BCd+fcUfGexaUUFtoc4H36+BDRFS5YDCliTTQnTSq5PTnZMjDYrD2vvGKvu3SBZ56xNvtBngScqzCeCEqZOxf++1/4wx9iHUk1UFholSzffWdX9JMmwV//as2w7r4bRo2yzlo//miPffuKi3UefNAme2/e3Ebq8+Ie56LGE0EpEyfauefSS2MdSZw6cMDa3P/wg5XhHzhQvC09vXj5+OPtUZbU1OjG6Zwr4okgxJ49Nrz0jTf6sBDlomq3Uv/zP9Y088UXbRyeW26xoRhSU20S5tBOW865KsMTQYi5c62I+pJLYh1JnNi719rYPv64teo57rjicfiTk2HChNjG55yLiM+VFeKtt6BBA6sodmXIz7fZdgD++EerwN2xw8r/166FceNiG59zrtw8EQQUFloiGDCg5LAyDqvwfeUVm4u3TRu7dQKr7P3oI1i1Cq6/3svTnItTXjQU8NVXsHkzXHRRrCOJsfx8qyxp2BA2bbIOXCtW2LbGjW2KtuBcvO3a2cM5F9c8EQT86182d8D558c6kkpWUACffmpl/cEBloYPh+efh5YtrTPFyJGWANLSvP2+c9WQJ4KAt96Cn/70yOYdiGs9etjtUEqKDcs8apSNvQ+WGV9/PbbxOeeizhMBNorBV1/ZMPXV3rx5Nk7Pa69ZZci4cVCnDlxwgQ+s5FyC8kQAvP22PVfr+oGdO+H22611z8knw/r11q5/xIhYR+acizFvNYTVD6SmQqdOsY4kSt56y+bcfeEFuO02WLzYO3c554ok/B3B3r3WGvL666vpcDYFBTZmT+PGNnPXGWfEOiLnXBWT8HcEH35oE1xdfHGsI6lAq1fDNdfYxApJSTBrFixc6EnAORdWwieCt96yOtKf/zzWkVSAdevs1ubUU60y+MsvbX3btt5LzjlXpoROBKqWCM47L847xRYUwHXX2WifU6bATTfZcA8J1ynCOXckEjoRLFpkTUfjtrXQ5s32nJRkY/mPGWMJ4MknrTOYc85FIKqJQEQGiMhKEVkjIuPL2KeviCwSkaUi8nE04ynt7betgviCCyrzU49SYSG8845d7bdpAytX2vqXX7YE0Lp1bONzzsWdqLUaEpEk4BngHCATWCAis1R1Wcg+jYBngQGq+oOItIhWPOEsXw4nnAAtKvVTj9Du3Ta71zPPWGVwq1Zw333QtKltr5ZNnpxzlSGazUd7AGtUdS2AiEwDBgLLQvb5FfCGqv4AoKpboxjPQTZtsiH048K+fXDHHXD66TaP5i9/6RXAzrkKEc2iodbA+pDlzMC6UB2AxiLykYgsFJGrwh1IREaJSIaIZGRlZVVYgBs3VvFEsGWLjXuhavNnrlplA8QNHepJwDlXYaKZCMKVVWip5ZrA6cCFwHnAvSLS4aA3qU5S1XRVTW/evHmFBbhpk5WwVDmqMHWqdXW+/35YFriJOtQcv845d4SimQgygbYhy22AjWH2eVdV96jqNmA+kBbFmIrs2QM5OVUwEaxaZbPjXHUVdOxoTZs6d451VM65aiyaiWAB0F5EUkWkFjAUmFVqnzeBn4lITRGpA5wJLI9iTEU2bbLnKlU0VFBgTZi++AKefhrmz7dk4JxzURS1ymJVzReRscB7QBIwWVWXisiNge0TVXW5iLwLfAMUAi+o6rfRiilUMBFUiTuC996Dvn2tV9vLL9usX8ceG+uonHMJIqqDzqnqbGB2qXUTSy3/H/B/0YwjnI2BQqqYJgJVawL6xz/Cs8/C6NHQs2cMA3LOJaKEHX005kVDqtYc9P/+D6691oaIcM65GEjoRFCrVvE87JVKFX7zG3jqKRsW4umnbVpI55yLgYQ9+2zcaMVCMemQu2aN9RL+7W/hz3/2JOCci6mEviOIWf1A+/Y2S9iJJ/rQEM65mEvYS9GYJILbb7c7ALCpIj0JOOeqgIRNBJU+vMRjj1nF8KpVlfihzjl3eAmZCPbtgx9/rMQ7gr//3SaNv+wyePzxSvpQ55yLTEImguB8LpWSCObMgREjrMPYlCk2iYxzzlUhCZkIgp3JKqVoaMUKGzxu5kyoXbsSPtA558onIRNBpQwvoYGBVseNg//8Bxo2jOKHOefckUvIRBD1O4Jt2+DMM2HePFtOSYnSBznn3NFLyESwaRPUrFk8y2OF2rsXLr4YlizxyWOcc3EhITuUbdpkg3tWeIfe/HwYNsyKgqZPh969K/gDnHOu4iVkIohKHwJVqw+YNcvGDho8uII/wDnnoiNhi4YqvKK4oAB277YRRceOreCDO+dc9CTkHcGmTdCnTwUftGZN6yegpadlds65qi3h7gj274ft2yuwaGjbNptjePlyGzvIRxJ1zsWZhDtrVWiv4sJCm2R+3jzIza2AAzrnXOWLaiIQkQEislJE1ojI+DDb+4rIThFZFHjcF814oIJnJpswAd55B554Arp1q4ADOudc5YuojkBEpgOTgXdUtTDC9yQBzwDnAJnAAhGZparLSu36iapeVI6Yj0qFzVX8ySdwzz1wxRVw441HHZdzzsVKpHcEzwG/AlaLyMMi0jGC9/QA1qjqWlU9AEwDBh5hnBWmwoaXeOwxm1hm0iSfV8A5F9ciSgSqOldVhwPdgXXAHBH5TESuEZHkMt7WGlgfspwZWFfaT0VksYi8IyKdyxH7Edm0yQYAbd78KA/06qvw/vvQoEGFxOWcc7EScR2BiDQFRgDXAV8DT2KJYU5ZbwmzrnTbyq+AE1Q1DXgamFnGZ48SkQwRycjKyoo05LA2boSWLY9iNOjCQqsYTkmBdu2OKhbnnKsKIkoEIvIG8AlQB7hYVS9R1VdVdRxQr4y3ZQJtQ5bbABtDd1DVHFXdHXg9G0gWkWalD6Sqk1Q1XVXTmx/lpfymTUdZUfzhh3aAhQuPKg7nnKsqIu1Q9mdV/TDcBlVNL+M9C4D2IpIKbACGYvUMRUTkWGCLqqqI9MAS0/YIYzoiGzfCCSccxQFeeMGeO0e9FMs55ypFpEVDp4pIo+CCiDQWkTGHeoOq5gNjgfeA5cBrqrpURG4UkWAzmyHAtyKyGHgKGKoa3a65RzW8xPbtMGMGXHmlTzLjnKs2Ir0juF5VnwkuqOoOEbkeePZQbwoU98wutW5iyOs/A3+OPNyjk5cHWVlHUTT08stw4ABce22FxuWcc7EU6R1BDZHiNpKBPgJxN9j+UfUqVrVioR49oEuXCo3LOediKdI7gveA10RkItby50bg3ahFFSVH3Yfg+edtsCLnnKtGIk0EdwA3AKOxZqHvAy9EK6hoOarhJUSgZ88Kjcc556qCSDuUFarqc6o6RFUvVdW/qGpBtIOraEc8vMSuXXDTTbB6dYXH5JxzsRZpP4L2IvJPEVkmImuDj2gHV9E2bbJRolu0KOcbX30Vnn3Whpx2zrlqJtLK4hex8YbygX7AFGBqtIKKlk2bLAnULO90PC+8AJ06edGQc65aijQRHKOqHwCiqt+r6v3A2dELKzo2bjyCYqHVq20y+pEjfXA551y1FOm1ca6I1MBGHx2L9RQubwFLzB3R8BJvvGHPl19e4fE451xVEOkdwW+wcYZuBk4Hfg1cHa2gouWI7ghE4IILoG3bw+/rnHNx6LCJINB57HJV3a2qmap6TaDl0BeVEF+Fyc+HrVuPIBHcfju8/XZUYnLOuargsIkg0Ez09NCexfFo61brHFyuoqHsbHuTc85VY5HWEXwNvCkirwN7gitV9Y2oRBUFR9SH4NJLbd6Bd+OuE7VzzkUs0kTQBBseOrSlkAJxkwjK3as4Kwvmz4e77opaTM45VxVElAhU9ZpoBxJtzZvDsGFw/PERvmHWLJuN7Je/jGpczjkXaxElAhF5kYOnmURVR1Z4RFHSs2c5+4O98QakpkLXrlGLyTnnqoJIi4beCnldGxhMqWknq5WcHJg7F8aN805kzrlqL9KioemhyyLyD2BuVCKqClJSYNo06Ngx1pE451zUlXfUnaD2QKSl7fEnJQUGD451FM45VykiHX10l4jkBB/Av7A5CqqfffvgoYfghx9iHYlzzlWKSOcjqK+qDUIeHUoXF4UjIgNEZKWIrBGR8YfY7wwRKRCRIeUJPirefx/uuQdWrox1JM45VykivSMYLCINQ5Ybicigw7wnCXgGOB/oBAwTkU5l7PcINh1m7L3xBjRuDH37xjoS55yrFJEOOvd7Vd0ZXFDVH4HfH+Y9PYA1qrpWVQ8A04CBYfYbB0wHtkYYS3R9/DGccw4kJ8c6EuecqxSRJoJw+x2uork1sD5kOTOwroiItMaaok481IFEZJSIZIhIRlZWVgThHqF9+6xuoHPn6H2Gc85VMZEmggwR+ZOInCQiJ4rI48DCw7wnXAP80p3SngDuONz8x6o6SVXTVTW9efPmEYZ8BH74waYvO+WU6H2Gc85VMZE2Hx0H3Au8Glh+H7jnMO/JBEIH8W/DwZ3Q0oFpgYFNmwEXiEi+qs6MMK6KdcopsHevDS3hnHMJItIOZXuAMlv9lGEB0F5EUrEZzYYCvyp13NTgaxF5CXgrZkkgqNwTGjvnXHyLtNXQHBFpFLLcWEQO2cpHVfOBsVhroOXAa6q6VERuFJEbjyboqHn4YbjvvlhH4ZxzlSrSy99mgZZCAKjqDhE57JzFqjobmF1qXdiKYVUdEWEs0TN9OjRqdPj9nHOuGom0srhQRIqGlBCRdoQZjTSuqVonMh9fyDmXYCK9I7gb+LeIfBxY/jkwKjohxcjmzbBrl7cYcs4lnEgri98VkXTs5L8IeBPYF83AKt2KFfbsicA5l2AinZjmOuAWrAnoIqAn8Dklp66Mb3v22PRlngiccwkm0jqCW4AzgO9VtR/QDYhiF98YuOgi+P77csxl6Zxz1UOkiSBXVXMBRCRFVVcAfunsnHPVQKSJIDPQj2AmMEdE3qS6TVV5zjkwYUKso3DOuUoXaWVxcLqu+0VkHtAQeDdqUVW2/fvhww+hV69YR+Kcc5Wu3OMpqOrHh98rzqxZY+MLeUWxcy4BRVo0VL0FZyPzROCcS0CeCKA4EXToENs4nHMuBjwRALRsCQMHQv36sY7EOecqnScCgJEjYWZsR792zrlY8USg6hPROOcSmieCrCwrEnr55VhH4pxzMeGJYOVKm56yWbNYR+KcczHhicCbjjrnEpwngpUrISXFB5tzziWsqCYCERkgIitFZI2IjA+zfaCIfCMii0QkQ0T6RDOesFasgPbtISmp0j/aOeeqgnIPMREpEUkCngHOATKBBSIyS1WXhez2ATBLVVVEugCvAZU7V+SAAXDgQKV+pHPOVSVRSwRAD2CNqq4FEJFpwECgKBGo6u6Q/esSi3mQb7qp0j/SOeeqklZBalAAABTWSURBVGgWDbUG1ocsZwbWlSAig0VkBfA2MDLcgURkVKDoKCMrqwLnw9m7F7KzK+54zjkXh6KZCCTMuoOu+FV1hqp2BAYBD4Y7kKpOUtV0VU1v3rx5xUU4Zw40bQoZGRV3TOecizPRTASZQNuQ5TYcYjIbVZ0PnCQildegP9h0tH37SvtI55yraqKZCBYA7UUkVURqAUOBWaE7iMjJIiKB192BWsD2KMZU0tq11pGsYcNK+0jnnKtqolZZrKr5IjIWeA9IAiar6lIRuTGwfSJwKXCViOQB+4ArVLXyKoyzsmzkUeecS2DRbDWEqs4GZpdaNzHk9SPAI9GM4ZCysnxoCedcwotqIqjyxozxjmTOuYSX2Ilg6NBYR+CcczGXuGMNFRbCN9/Azp2xjsQ552IqcRPB9u2QlgZTp8Y6Eueci6nETQTBHspeWeycS3CJmwi2bbPniuyp7JxzcShxE0HwjsATgXMuwXki8ETgnEtwiZsI+vWD55/3OgLnXMJL3H4Ep5zi8xQ75xyJfEewaBEsWRLrKJxzLuYS947gd7+D3bvh889jHYlzzsVU4t4RZGV5RbFzzuGJINZROOdczCVmIlD1ROCccwGJmQhyciAvz5uOOucciVpZXLs2zJ4NHTrEOhLnnIu5xEwEKSlw/vmxjsI556qExCwa+uEHePNNaz7qnHMJLqqJQEQGiMhKEVkjIuPDbB8uIt8EHp+JSFo04ykydy4MGlQ8AqlzziWwqCUCEUkCngHOBzoBw0SkU6ndvgPOUtUuwIPApGjFU4LPReCcc0WieUfQA1ijqmtV9QAwDRgYuoOqfqaqOwKLXwBtohhPsawsqzCuW7dSPs4556qyaCaC1sD6kOXMwLqyXAu8E26DiIwSkQwRycgKXs0fjW3brA+ByNEfyznn4lw0E0G4s6yG3VGkH5YI7gi3XVUnqWq6qqY3r4hOYN6ZzDnnikSz+Wgm0DZkuQ2wsfROItIFeAE4X1W3RzGeYk88AXv2VMpHOedcVRfNRLAAaC8iqcAGYCjwq9AdROR44A3gSlVdFcVYSmrfvtI+yjnnqrqoFQ2paj4wFngPWA68pqpLReRGEbkxsNt9QFPgWRFZJCIZ0YqnhL/8xeYjcM45h6iGLbavstLT0zUj4yjyRW4uHHMMPPQQ3HVXxQXmnHNVmIgsVNX0cNsSb4iJYCcyryx2CSQvL4/MzExyc3NjHYqLstq1a9OmTRuSk5Mjfk/iJYJg81NPBC6BZGZmUr9+fdq1a4d4s+lqS1XZvn07mZmZpKamRvy+xBtryBOBS0C5ubk0bdrUk0A1JyI0bdq03Hd+iZsIfHgJl2A8CSSGI/l3TrxEMHgwLF8O5bhtcs656izxEkGdOtCxI9SqFetInEsY27dvp2vXrnTt2pVjjz2W1q1bFy0fOHDgkO/NyMjg5ptvPuxn9OrVq6LCTTiJV1n85ptWPHTddbGOxLmE0bRpUxYF+u7cf//91KtXj9tuu61oe35+PjVrhj8dpaenk54ettVjCZ999lnFBFuJCgoKSEpKinUYCXhH8Le/2RATziWyvn0Pfjz7rG3buzf89pdesu3bth287QiMGDGCW2+9lX79+nHHHXfw5Zdf0qtXL7p160avXr1YuXIlAB999BEXXXQRYElk5MiR9O3blxNPPJGnnnqq6Hj16tUr2r9v374MGTKEjh07Mnz4cIL9pWbPnk3Hjh3p06cPN998c9FxQ61bt46f/exndO/ene7du5dIMBMmTOC0004jLS2N8eNtipU1a9bwi1/8grS0NLp3785///vfEjEDjB07lpcCf7927drxhz/8gT59+vD666/z/PPPc8YZZ5CWlsall17K3r17AdiyZQuDBw8mLS2NtLQ0PvvsM+69916efPLJouPefffdJf4GRyrx7gh8wDnnqoxVq1Yxd+5ckpKSyMnJYf78+dSsWZO5c+dy1113MX369IPes2LFCubNm8euXbs45ZRTGD169EFt5r/++muWLl3KcccdR+/evfn0009JT0/nhhtuYP78+aSmpjJs2LCwMbVo0YI5c+ZQu3ZtVq9ezbBhw8jIyOCdd95h5syZ/Oc//6FOnTpkZ2cDMHz4cMaPH8/gwYPJzc2lsLCQ9evXhz12UO3atfn3v/8NWLHZ9ddfD8A999zDX//6V8aNG8fNN9/MWWedxYwZMygoKGD37t0cd9xx/PKXv+SWW26hsLCQadOm8eWXX5b7715aYiaC006LdRTOxdZHH5W9rU6dQ29v1uzQ28vhsssuKyoa2blzJ1dffTWrV69GRMjLywv7ngsvvJCUlBRSUlJo0aIFW7ZsoU2bklOZ9OjRo2hd165dWbduHfXq1ePEE08sal8/bNgwJk06eC6svLw8xo4dy6JFi0hKSmLVKhsGbe7cuVxzzTXUqVMHgCZNmrBr1y42bNjA4MGDATvBR+KKK64oev3tt99yzz338OOPP7J7927OO+88AD788EOmTJkCQFJSEg0bNqRhw4Y0bdqUr7/+mi1bttCtWzeaNm0a0WceSmImAr8jcK5KqBsyOdS9995Lv379mDFjBuvWraNvGUVOKSkpRa+TkpLIz8+PaJ9Ih9N5/PHHadmyJYsXL6awsLDo5K6qBzXNLOuYNWvWpLCwsGi5dLv+0O89YsQIZs6cSVpaGi+99BIfHSbJXnfddbz00kts3ryZkSNHRvSdDiex6gjy82HHDk8EzlVBO3fupHVrm7sqWJ5ekTp27MjatWtZt24dAK+++mqZcbRq1YoaNWowdepUCgoKADj33HOZPHlyURl+dnY2DRo0oE2bNsycOROA/fv3s3fvXk444QSWLVvG/v372blzJx988EGZce3atYtWrVqRl5fHK6+8UrS+f//+PPfcc4BVKufk5AAwePBg3n33XRYsWFB093C0EisRJCXBzp0Q0lrBOVc13H777dx555307t276ORbkY455hieffZZBgwYQJ8+fWjZsiUNGzY8aL8xY8bwt7/9jZ49e7Jq1aqiq/cBAwZwySWXkJ6eTteuXXn00UcBmDp1Kk899RRdunShV69ebN68mbZt23L55ZfTpUsXhg8fTrdu3cqM68EHH+TMM8/knHPOoWPHjkXrn3zySebNm8dpp53G6aefztKlSwGoVasW/fr14/LLL6+wFkeJN/qocwlo+fLlnHrqqbEOI+Z2795NvXr1UFVuuukm2rdvz29/+9tYh1UuhYWFdO/enddff532ZcytEu7f+1CjjybWHcHy5XY38P33sY7EORcDzz//PF27dqVz587s3LmTG264IdYhlcuyZcs4+eST6d+/f5lJ4EgkVmXxt9/CY4/BVVfFOhLnXAz89re/jbs7gFCdOnVi7dq1FX7cxLoj8JFHnXPuIImVCIKT0vjIo845VySqiUBEBojIShFZIyLjw2zvKCKfi8h+EYl+U56sLGjUCMoxc49zzlV3UasjEJEk4BngHCATWCAis1R1Wchu2cDNwKBoxVFCTo4XCznnXCnRvCPoAaxR1bWqegCYBgwM3UFVt6rqAiB8X/KK9re/QaAtrnOu8vTt25f33nuvxLonnniCMWPGHPI93lS8ckQzEbQGQkdeygysKzcRGSUiGSKSkRWs8D1SXizkXKUbNmwY06ZNK7Fu2rRpZQ78VhWEG7qiuopm89Fw86UdUe81VZ0ETALrUHbEEY0ZAz//OQwdesSHcC7e/eY3EJgaoMJ07Xro0d2HDBnCPffcw/79+0lJSWHdunVs3LiRPn36MHr0aBYsWMC+ffsYMmQIDzzwwCE/6w9/+AP/+te/2LdvH7169eIvf/kLIsKaNWu48cYbycrKIikpiddff52TTjqJCRMmMHXqVGrUqMH555/Pww8/TN++fXn00UdJT09n27ZtpKens27dOl566SXefvttcnNz2bNnD7NmzWLgwIHs2LGDvLw8/vjHPzJwoBVsTJkyhUcffRQRoUuXLjz77LN06dKFVatWkZycTE5ODl26dGH16tUHjY5a1UQzEWQCbUOW2wAbo/h5h6YKL7wADRt6InCukjVt2pQePXrw7rvvMnDgQKZNm8YVV1yBiPDQQw/RpEkTCgoK6N+/P9988w1dunQp81hjx47lvvvuA+DKK6/krbfe4uKLLw47HHRZQ0cfyueff84333xDkyZNyM/PZ8aMGTRo0IBt27bRs2dPLrnkEpYtW8ZDDz3Ep59+SrNmzcjOzqZ+/fr07duXt99+m0GDBjFt2jQuvfTSKp8EILqJYAHQXkRSgQ3AUOBXUfy8Q8vJgbw8ryx2CS9W8zIFi4eCiWDy5MkAvPbaa0yaNIn8/Hw2bdrEsmXLDpkI5s2bx4QJE9i7dy/Z2dl07tyZvn37hh0OOtzQ0YdzzjnnFO2nqtx1113Mnz+fGjVqsGHDBrZs2cKHH37IkCFDaBZoih7c/7rrrmPChAkMGjSIF198keeff/4I/1qVK2qJQFXzRWQs8B6QBExW1aUicmNg+0QRORbIABoAhSLyG6CTquZUeEDemcy5mBo0aBC33norX331Ffv27aN79+589913PProoyxYsIDGjRszYsSIg4ZsDpWbm8uYMWPIyMigbdu23H///eTm5pY5HHS4oaOh5DDRhxoi+pVXXiErK4uFCxeSnJxMu3btij4v3HF79+7NunXr+PjjjykoKOAnP/lJRH+bWItqPwJVna2qHVT1JFV9KLBuoqpODLzerKptVLWBqjYKvK74JADFicA7kzkXE/Xq1aNv376MHDmyqJI4JyeHunXr0rBhQ7Zs2cI777xzyGMET9rNmjVj9+7d/POf/wQoczjocENHg00XuXDhQoCiY4Szc+dOWrRoQXJyMvPmzeP7wDhl/fv357XXXmP79u0ljgtw1VVXMWzYMK655pry/YFiKHF6Fu/bB02bQosWsY7EuYQ1bNgwFi9ezNBAPV1aWhrdunWjc+fOjBw5kt69ex/y/Y0aNeL666/ntNNOY9CgQZxxxhlF28INB13W0NG33XYbzz33HL169WJbcMSBMIYPH05GRgbp6em88sorRcNEd+7cmbvvvpuzzjqLtLQ0br311hLv2bFjR5VuEVWaD0PtXALwYagrzz//+U/efPNNpk6dGrMYyjsMdWKNPuqcc1E0btw43nnnHWbPnh3rUMrFE4FzzlWQp59+OtYhHJHEqSNwLsHFWzGwOzJH8u/sicC5BFC7dm22b9/uyaCaU1W2b99e1I8iUl405FwCaNOmDZmZmRz1WF2uyqtduzZt2rQp13s8ETiXAJKTk0lNTY11GK6K8qIh55xLcJ4InHMuwXkicM65BBd3PYtFJAv4PsLdmwFl9x+v2uI5dojv+OM5dojv+OM5dqja8Z+gqmFH3Yy7RFAeIpJRVpfqqi6eY4f4jj+eY4f4jj+eY4f4jd+LhpxzLsF5InDOuQRX3RPBpFgHcBTiOXaI7/jjOXaI7/jjOXaI0/irdR2Bc865w6vudwTOOecOwxOBc84luGqZCERkgIisFJE1IjI+1vEcjohMFpGtIvJtyLomIjJHRFYHnhvHMsayiEhbEZknIstFZKmI3BJYHy/x1xaRL0VkcSD+BwLr4yJ+ABFJEpGvReStwHI8xb5ORJaIyCIRyQisi4v4RaSRiPxTRFYEfv8/jZfYS6t2iUBEkoBngPOBTsAwEekU26gO6yVgQKl144EPVLU98EFguSrKB/6fqp4K9ARuCvy94yX+/cDZqpoGdAUGiEhP4id+gFuA5SHL8RQ7QD9V7RrS/j5e4n8SeFdVOwJp2L9BvMRekqpWqwfwU+C9kOU7gTtjHVcEcbcDvg1ZXgm0CrxuBayMdYwRfo83gXPiMX6gDvAVcGa8xA+0wU44ZwNvxdtvB1gHNCu1rsrHDzQAviPQ4CaeYg/3qHZ3BEBrYH3IcmZgXbxpqaqbAALPLWIcz2GJSDugG/Af4ij+QNHKImArMEdV4yn+J4DbgcKQdfESO4AC74vIQhEZFVgXD/GfCGQBLwaK5V4QkbrER+wHqY6JQMKs8zayUSYi9YDpwG9UNSfW8ZSHqhaoalfs6rqHiPwk1jFFQkQuAraq6sJYx3IUeqtqd6wo9yYR+XmsA4pQTaA78JyqdgP2EC/FQGFUx0SQCbQNWW4DbIxRLEdji4i0Agg8b41xPGUSkWQsCbyiqm8EVsdN/EGq+iPwEVZfEw/x9wYuEZF1wDTgbBF5mfiIHQBV3Rh43grMAHoQH/FnApmBu0eAf2KJIR5iP0h1TAQLgPYikioitYChwKwYx3QkZgFXB15fjZW9VzkiIsBfgeWq+qeQTfESf3MRaRR4fQzwC2AFcRC/qt6pqm1UtR32O/9QVX9NHMQOICJ1RaR+8DVwLvAtcRC/qm4G1ovIKYFV/YFlxEHsYcW6kiJKFTkXAKuA/wJ3xzqeCOL9B7AJyMOuNK4FmmKVgKsDz01iHWcZsffBit6+ARYFHhfEUfxdgK8D8X8L3BdYHxfxh3yPvhRXFsdF7Fg5++LAY2nw/2ocxd8VyAj8dmYCjeMl9tIPH2LCOecSXHUsGnLOOVcOngiccy7BeSJwzrkE54nAOecSnCcC55xLcJ4InCtFRAoCo2EGHxXWY1RE2oWOMutcVVAz1gE4VwXtUxtywrmE4HcEzkUoMHb+I4H5C74UkZMD608QkQ9E5JvA8/GB9S1FZEZgroPFItIrcKgkEXk+MP/B+4Eezc7FjCcC5w52TKmioStCtuWoag/gz9jInwReT1HVLsArwFOB9U8BH6vNddAd6z0L0B54RlU7Az8Cl0b5+zh3SN6z2LlSRGS3qtYLs34dNonN2sBAe5tVtamIbMPGoM8LrN+kqs1EJAtoo6r7Q47RDhvqun1g+Q4gWVX/GP1v5lx4fkfgXPloGa/L2iec/SGvC/C6OhdjngicK58rQp4/D7z+DBv9E2A48O/A6w+A0VA0+U2DygrSufLwKxHnDnZMYMayoHdVNdiENEVE/oNdRA0LrLsZmCwiv8NmrbomsP4WYJKIXItd+Y/GRpl1rkrxOgLnIhSoI0hX1W2xjsW5iuRFQ845l+D8jsA55xKc3xE451yC80TgnHMJzhOBc84lOE8EzjmX4DwROOdcgvv/9yFpeFjNxzkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_diagnostic_plot(model,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Zhiqing\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: G:/Github/Dogs_breed_classification/resnet50_2/assets\n"
     ]
    }
   ],
   "source": [
    "save_path = 'G:/Github/Dogs_breed_classification/resnet50_2/'\n",
    "tf.keras.models.save_model(model,save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model using feature extraction only is not ideal. The performance is ok but it is not achieving its best for resnet 50 models\n",
    "\n",
    "We will try to unfreeze resnet 50 and train again..\n",
    "\n",
    "Meanwhile, we can also explore: deeper models resnet 101,152 or other architectures that is supposed to work better than Resnet50 (Xception/Inception/InceptionResNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
