{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2\n",
    "from PIL import Image \n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH=224\n",
    "IMG_HEIGHT=224\n",
    "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT)\n",
    "BATCH_SIZE = 25\n",
    "IMG_DIR = pathlib.Path('G:\\Github\\standford-dogs\\cropped')\n",
    "TRAIN_DIR = 'G:/Github/standford-dogs/cropped/train'\n",
    "VAL_DIR = 'G:/Github/standford-dogs/cropped/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifiy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Specify the values for all arguments to data_generator_with_aug.\n",
    "data_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                              horizontal_flip = True,\n",
    "                                              width_shift_range = 0.2,\n",
    "                                              height_shift_range = 0.2\n",
    "                                                )\n",
    "            \n",
    "data_generator_no_aug = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16464 images belonging to 120 classes.\n",
      "Found 4116 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator_with_aug.flow_from_directory(\n",
    "                                        directory=TRAIN_DIR,\n",
    "                                        target_size=IMG_DIM,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "validation_generator = data_generator_no_aug.flow_from_directory(\n",
    "                                        directory=VAL_DIR,\n",
    "                                        target_size=IMG_DIM,batch_size=BATCH_SIZE,\n",
    "                                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "resnet = ResNet50(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT,IMG_WIDTH,3),pooling='max')\n",
    "\n",
    "output = resnet.layers[-1].output\n",
    "output = tf.keras.layers.Flatten()(output)\n",
    "resnet = Model(resnet.input, output)\n",
    "\n",
    "res_name = []\n",
    "for layer in resnet.layers:\n",
    "    res_name.append(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv5_block2_1_conv',\n",
       " 'conv5_block2_1_bn',\n",
       " 'conv5_block2_1_relu',\n",
       " 'conv5_block2_2_conv',\n",
       " 'conv5_block2_2_bn',\n",
       " 'conv5_block2_2_relu',\n",
       " 'conv5_block2_3_conv',\n",
       " 'conv5_block2_3_bn',\n",
       " 'conv5_block2_add',\n",
       " 'conv5_block2_out',\n",
       " 'conv5_block3_1_conv',\n",
       " 'conv5_block3_1_bn',\n",
       " 'conv5_block3_1_relu',\n",
       " 'conv5_block3_2_conv',\n",
       " 'conv5_block3_2_bn',\n",
       " 'conv5_block3_2_relu',\n",
       " 'conv5_block3_3_conv',\n",
       " 'conv5_block3_3_bn',\n",
       " 'conv5_block3_add',\n",
       " 'conv5_block3_out',\n",
       " 'max_pool',\n",
       " 'flatten']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_name[-22:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trainable = False\n",
    "for layer in resnet.layers:\n",
    "    if layer.name in res_name[-22:]:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool (GlobalMaxPooling2D)   (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 8,931,328\n",
      "Non-trainable params: 14,656,384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Model)                (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               123000    \n",
      "=================================================================\n",
      "Total params: 26,858,488\n",
      "Trainable params: 12,202,104\n",
      "Non-trainable params: 14,656,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "num_classes = 120\n",
    "\n",
    "model = Sequential()\n",
    "model.add(resnet)\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to use resnet50 as feature extraction, hence adding pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8,\n",
    "                                              restore_best_weights=False\n",
    "                                              )\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                   factor=0.2,\n",
    "                                   patience=4,\n",
    "                                   verbose=1,\n",
    "                                   min_delta=1e-4,min_lr = 1e-6,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics=['accuracy',tfa.metrics.F1Score(num_classes=num_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 659.0 steps, validate for 165.0 steps\n",
      "Epoch 1/100\n",
      "659/659 [==============================] - 229s 348ms/step - loss: 4.0446 - accuracy: 0.1939 - f1_score: 0.1857 - val_loss: 1.3908 - val_accuracy: 0.6086 - val_f1_score: 0.5769\n",
      "Epoch 2/100\n",
      "659/659 [==============================] - 217s 329ms/step - loss: 1.8778 - accuracy: 0.4955 - f1_score: 0.4864 - val_loss: 1.0513 - val_accuracy: 0.6871 - val_f1_score: 0.6671\n",
      "Epoch 3/100\n",
      "659/659 [==============================] - 214s 324ms/step - loss: 1.4062 - accuracy: 0.6059 - f1_score: 0.5991 - val_loss: 1.0158 - val_accuracy: 0.6902 - val_f1_score: 0.6771\n",
      "Epoch 4/100\n",
      "659/659 [==============================] - 210s 318ms/step - loss: 1.1620 - accuracy: 0.6662 - f1_score: 0.6615 - val_loss: 0.9198 - val_accuracy: 0.7269 - val_f1_score: 0.7089\n",
      "Epoch 5/100\n",
      "659/659 [==============================] - 202s 306ms/step - loss: 1.0047 - accuracy: 0.7057 - f1_score: 0.7003 - val_loss: 0.8431 - val_accuracy: 0.7456 - val_f1_score: 0.7380\n",
      "Epoch 6/100\n",
      "659/659 [==============================] - 202s 306ms/step - loss: 0.8885 - accuracy: 0.7355 - f1_score: 0.7314 - val_loss: 0.8794 - val_accuracy: 0.7459 - val_f1_score: 0.7382\n",
      "Epoch 7/100\n",
      "659/659 [==============================] - 201s 305ms/step - loss: 0.7759 - accuracy: 0.7631 - f1_score: 0.7600 - val_loss: 0.8781 - val_accuracy: 0.7420 - val_f1_score: 0.7355\n",
      "Epoch 8/100\n",
      "659/659 [==============================] - 202s 306ms/step - loss: 0.6989 - accuracy: 0.7840 - f1_score: 0.7807 - val_loss: 0.8813 - val_accuracy: 0.7515 - val_f1_score: 0.7398\n",
      "Epoch 9/100\n",
      "658/659 [============================>.] - ETA: 0s - loss: 0.6406 - accuracy: 0.8012 - f1_score: 0.7984\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "659/659 [==============================] - 201s 306ms/step - loss: 0.6403 - accuracy: 0.8014 - f1_score: 0.7986 - val_loss: 0.8564 - val_accuracy: 0.7549 - val_f1_score: 0.7413\n",
      "Epoch 10/100\n",
      "659/659 [==============================] - 201s 306ms/step - loss: 0.4276 - accuracy: 0.8635 - f1_score: 0.8610 - val_loss: 0.7386 - val_accuracy: 0.7894 - val_f1_score: 0.7819\n",
      "Epoch 11/100\n",
      "659/659 [==============================] - 201s 305ms/step - loss: 0.3535 - accuracy: 0.8850 - f1_score: 0.8830 - val_loss: 0.7565 - val_accuracy: 0.7884 - val_f1_score: 0.7815\n",
      "Epoch 12/100\n",
      "659/659 [==============================] - 201s 305ms/step - loss: 0.3213 - accuracy: 0.8935 - f1_score: 0.8913 - val_loss: 0.7621 - val_accuracy: 0.7874 - val_f1_score: 0.7810\n",
      "Epoch 13/100\n",
      "659/659 [==============================] - 202s 306ms/step - loss: 0.2861 - accuracy: 0.9066 - f1_score: 0.9047 - val_loss: 0.7482 - val_accuracy: 0.7935 - val_f1_score: 0.7874\n",
      "Epoch 14/100\n",
      "658/659 [============================>.] - ETA: 0s - loss: 0.2633 - accuracy: 0.9125 - f1_score: 0.9109\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "659/659 [==============================] - 201s 306ms/step - loss: 0.2634 - accuracy: 0.9125 - f1_score: 0.9109 - val_loss: 0.7748 - val_accuracy: 0.7901 - val_f1_score: 0.7826\n",
      "Epoch 15/100\n",
      "659/659 [==============================] - 202s 306ms/step - loss: 0.2349 - accuracy: 0.9208 - f1_score: 0.9198 - val_loss: 0.7646 - val_accuracy: 0.7954 - val_f1_score: 0.7880\n",
      "Epoch 16/100\n",
      "659/659 [==============================] - 202s 307ms/step - loss: 0.2224 - accuracy: 0.9255 - f1_score: 0.9245 - val_loss: 0.7562 - val_accuracy: 0.7962 - val_f1_score: 0.7888\n",
      "Epoch 17/100\n",
      "659/659 [==============================] - 201s 306ms/step - loss: 0.2178 - accuracy: 0.9269 - f1_score: 0.9256 - val_loss: 0.7525 - val_accuracy: 0.7969 - val_f1_score: 0.7897\n",
      "Epoch 18/100\n",
      "658/659 [============================>.] - ETA: 0s - loss: 0.2124 - accuracy: 0.9288 - f1_score: 0.9277\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "659/659 [==============================] - 201s 305ms/step - loss: 0.2125 - accuracy: 0.9287 - f1_score: 0.9276 - val_loss: 0.7602 - val_accuracy: 0.7952 - val_f1_score: 0.7886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1af681d0c18>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,steps_per_epoch=np.ceil(float(16464) / float(BATCH_SIZE)),\n",
    "                        epochs = 100,callbacks=[early_stop,reduce_lr],\n",
    "                          validation_steps=np.ceil(float(4116) / float(BATCH_SIZE)),\n",
    "                        validation_data = validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagnostic_plot(model,name):\n",
    "    training_loss = model.history.history[name]\n",
    "    test_loss = model.history.history[f'val_{name}']\n",
    "\n",
    "    # Create count of the number of epochs\n",
    "    epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    # Visualize loss history\n",
    "    plt.plot(epoch_count, training_loss, 'r--')\n",
    "    plt.plot(epoch_count, test_loss, 'b-')\n",
    "    plt.legend([f'Training {name}', f'Val {name}'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_diagnostic_plot(model,'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_diagnostic_plot(model,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Zhiqing\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: G:/Github/Dogs_breed_classification/resnet50_3/assets\n"
     ]
    }
   ],
   "source": [
    "save_path = 'G:/Github/Dogs_breed_classification/resnet50_3/'\n",
    "tf.keras.models.save_model(model,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_history = model.history.history['f1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = [np.mean(item) for item in  f1_score_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_val_hist = model.history.history['val_f1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_val = [np.mean(item) for item in  f1_score_val_hist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'F1 Score')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loss = f1_scores\n",
    "test_loss = f1_scores_val\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    # Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training F1 score', 'Val F1 score'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result slightly improves v.s. our first attempt but it is clearly overfitted when we added more Epochs \n",
    "\n",
    "=> model indicates high variability \n",
    "\n",
    "We can:\n",
    "   * Add more data (increase train split ratio, probbaly 9:1 would work for this set)\n",
    "   * Regularization (try more drop outs and strides)\n",
    "   * Or We shall move on with other model structures other than Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
