{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2\n",
    "from PIL import Image \n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH=224\n",
    "IMG_HEIGHT=224\n",
    "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT)\n",
    "BATCH_SIZE = 25\n",
    "IMG_DIR = pathlib.Path('G:\\Github\\standford-dogs\\cropped')\n",
    "TRAIN_DIR = 'G:/Github/standford-dogs/cropped/train'\n",
    "VAL_DIR = 'G:/Github/standford-dogs/cropped/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifiy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Specify the values for all arguments to data_generator_with_aug.\n",
    "data_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                              horizontal_flip = True,\n",
    "                                              width_shift_range = 0.2,\n",
    "                                              height_shift_range = 0.2\n",
    "                                                )\n",
    "            \n",
    "data_generator_no_aug = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16464 images belonging to 120 classes.\n",
      "Found 4116 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator_with_aug.flow_from_directory(\n",
    "                                        directory=TRAIN_DIR,\n",
    "                                        target_size=IMG_DIM,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "validation_generator = data_generator_no_aug.flow_from_directory(\n",
    "                                        directory=VAL_DIR,\n",
    "                                        target_size=IMG_DIM,batch_size=BATCH_SIZE,\n",
    "                                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "resnet = ResNet50(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT,IMG_WIDTH,3),pooling='max')\n",
    "\n",
    "output = resnet.layers[-1].output\n",
    "output = tf.keras.layers.Flatten()(output)\n",
    "resnet = Model(resnet.input, output)\n",
    "\n",
    "res_name = []\n",
    "for layer in resnet.layers:\n",
    "    res_name.append(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv5_block2_1_conv',\n",
       " 'conv5_block2_1_bn',\n",
       " 'conv5_block2_1_relu',\n",
       " 'conv5_block2_2_conv',\n",
       " 'conv5_block2_2_bn',\n",
       " 'conv5_block2_2_relu',\n",
       " 'conv5_block2_3_conv',\n",
       " 'conv5_block2_3_bn',\n",
       " 'conv5_block2_add',\n",
       " 'conv5_block2_out',\n",
       " 'conv5_block3_1_conv',\n",
       " 'conv5_block3_1_bn',\n",
       " 'conv5_block3_1_relu',\n",
       " 'conv5_block3_2_conv',\n",
       " 'conv5_block3_2_bn',\n",
       " 'conv5_block3_2_relu',\n",
       " 'conv5_block3_3_conv',\n",
       " 'conv5_block3_3_bn',\n",
       " 'conv5_block3_add',\n",
       " 'conv5_block3_out',\n",
       " 'max_pool',\n",
       " 'flatten']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_name[-22:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trainable = False\n",
    "for layer in resnet.layers:\n",
    "    if layer.name in res_name[-22:]:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool (GlobalMaxPooling2D)   (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 8,931,328\n",
      "Non-trainable params: 14,656,384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Model)                (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               123000    \n",
      "=================================================================\n",
      "Total params: 26,858,488\n",
      "Trainable params: 12,202,104\n",
      "Non-trainable params: 14,656,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "num_classes = 120\n",
    "\n",
    "model = Sequential()\n",
    "model.add(resnet)\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to use resnet50 as feature extraction, hence adding pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8,\n",
    "                                              restore_best_weights=False\n",
    "                                              )\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                   factor=0.2,\n",
    "                                   patience=4,\n",
    "                                   verbose=1,\n",
    "                                   min_delta=5*1e-3,min_lr = 5*1e-7,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics=['accuracy',tfa.metrics.F1Score(num_classes=num_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 659.0 steps, validate for 165.0 steps\n",
      "Epoch 1/100\n",
      "659/659 [==============================] - 296s 449ms/step - loss: 5.5431 - accuracy: 0.0202 - f1_score: 0.0173 - val_loss: 4.1658 - val_accuracy: 0.1319 - val_f1_score: 0.0800\n",
      "Epoch 2/100\n",
      "659/659 [==============================] - 268s 407ms/step - loss: 4.0111 - accuracy: 0.1269 - f1_score: 0.1048 - val_loss: 2.3865 - val_accuracy: 0.4320 - val_f1_score: 0.3750\n",
      "Epoch 3/100\n",
      "659/659 [==============================] - 205s 311ms/step - loss: 3.0336 - accuracy: 0.2769 - f1_score: 0.2590 - val_loss: 1.6469 - val_accuracy: 0.5624 - val_f1_score: 0.5182\n",
      "Epoch 4/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 2.3992 - accuracy: 0.3892 - f1_score: 0.3745 - val_loss: 1.2363 - val_accuracy: 0.6567 - val_f1_score: 0.6370\n",
      "Epoch 5/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 2.0096 - accuracy: 0.4670 - f1_score: 0.4543 - val_loss: 1.1838 - val_accuracy: 0.6672 - val_f1_score: 0.6471\n",
      "Epoch 6/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 1.7839 - accuracy: 0.5143 - f1_score: 0.5046 - val_loss: 1.0648 - val_accuracy: 0.6854 - val_f1_score: 0.6686\n",
      "Epoch 7/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 1.5882 - accuracy: 0.5542 - f1_score: 0.5454 - val_loss: 0.9339 - val_accuracy: 0.7184 - val_f1_score: 0.7012\n",
      "Epoch 8/100\n",
      "659/659 [==============================] - 203s 309ms/step - loss: 1.4375 - accuracy: 0.5912 - f1_score: 0.5828 - val_loss: 0.9488 - val_accuracy: 0.7301 - val_f1_score: 0.7171\n",
      "Epoch 9/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 1.3062 - accuracy: 0.6251 - f1_score: 0.6175 - val_loss: 0.8720 - val_accuracy: 0.7383 - val_f1_score: 0.7249\n",
      "Epoch 10/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 1.2266 - accuracy: 0.6455 - f1_score: 0.6382 - val_loss: 0.9163 - val_accuracy: 0.7354 - val_f1_score: 0.7265\n",
      "Epoch 11/100\n",
      "659/659 [==============================] - 205s 311ms/step - loss: 1.1193 - accuracy: 0.6729 - f1_score: 0.6661 - val_loss: 0.9379 - val_accuracy: 0.7328 - val_f1_score: 0.7198\n",
      "Epoch 12/100\n",
      "659/659 [==============================] - 205s 310ms/step - loss: 1.0341 - accuracy: 0.6971 - f1_score: 0.6907 - val_loss: 0.9313 - val_accuracy: 0.7349 - val_f1_score: 0.7238\n",
      "Epoch 13/100\n",
      "658/659 [============================>.] - ETA: 0s - loss: 0.9604 - accuracy: 0.7132 - f1_score: 0.7069\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "659/659 [==============================] - 205s 311ms/step - loss: 0.9601 - accuracy: 0.7132 - f1_score: 0.7069 - val_loss: 0.8695 - val_accuracy: 0.7561 - val_f1_score: 0.7485\n",
      "Epoch 14/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 0.7439 - accuracy: 0.7691 - f1_score: 0.7641 - val_loss: 0.8073 - val_accuracy: 0.7638 - val_f1_score: 0.7565\n",
      "Epoch 15/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 0.6712 - accuracy: 0.7891 - f1_score: 0.7849 - val_loss: 0.7824 - val_accuracy: 0.7772 - val_f1_score: 0.7685\n",
      "Epoch 16/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 0.6449 - accuracy: 0.7986 - f1_score: 0.7940 - val_loss: 0.8214 - val_accuracy: 0.7677 - val_f1_score: 0.7595\n",
      "Epoch 17/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 0.6159 - accuracy: 0.8116 - f1_score: 0.8076 - val_loss: 0.7960 - val_accuracy: 0.7792 - val_f1_score: 0.7718\n",
      "Epoch 18/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 0.5892 - accuracy: 0.8116 - f1_score: 0.8069 - val_loss: 0.8233 - val_accuracy: 0.7745 - val_f1_score: 0.7667\n",
      "Epoch 19/100\n",
      "658/659 [============================>.] - ETA: 0s - loss: 0.5606 - accuracy: 0.8201 - f1_score: 0.8161\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 0.5611 - accuracy: 0.8200 - f1_score: 0.8160 - val_loss: 0.8144 - val_accuracy: 0.7728 - val_f1_score: 0.7657\n",
      "Epoch 20/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 0.5184 - accuracy: 0.8303 - f1_score: 0.8266 - val_loss: 0.7928 - val_accuracy: 0.7811 - val_f1_score: 0.7735\n",
      "Epoch 21/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 0.5102 - accuracy: 0.8376 - f1_score: 0.8336 - val_loss: 0.7911 - val_accuracy: 0.7811 - val_f1_score: 0.7734\n",
      "Epoch 22/100\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 0.5051 - accuracy: 0.8380 - f1_score: 0.8338 - val_loss: 0.7940 - val_accuracy: 0.7767 - val_f1_score: 0.7701\n",
      "Epoch 23/100\n",
      "658/659 [============================>.] - ETA: 0s - loss: 0.4790 - accuracy: 0.8432 - f1_score: 0.8394\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "659/659 [==============================] - 204s 309ms/step - loss: 0.4786 - accuracy: 0.8433 - f1_score: 0.8395 - val_loss: 0.7900 - val_accuracy: 0.7823 - val_f1_score: 0.7744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20e6cc0ebe0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,steps_per_epoch=np.ceil(float(16464) / float(BATCH_SIZE)),\n",
    "                        epochs = 100,callbacks=[early_stop,reduce_lr],\n",
    "                          validation_steps=np.ceil(float(4116) / float(BATCH_SIZE)),\n",
    "                        validation_data = validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagnostic_plot(model,name):\n",
    "    training_loss = model.history.history[name]\n",
    "    test_loss = model.history.history[f'val_{name}']\n",
    "\n",
    "    # Create count of the number of epochs\n",
    "    epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    # Visualize loss history\n",
    "    plt.plot(epoch_count, training_loss, 'r--')\n",
    "    plt.plot(epoch_count, test_loss, 'b-')\n",
    "    plt.legend([f'Training {name}', f'Val {name}'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_diagnostic_plot(model,'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_diagnostic_plot(model,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Zhiqing\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: G:/Github/Dogs_breed_classification/resnet50_4/assets\n"
     ]
    }
   ],
   "source": [
    "save_path = 'G:/Github/Dogs_breed_classification/resnet50_4/'\n",
    "tf.keras.models.save_model(model,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_history = model.history.history['f1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = [np.mean(item) for item in  f1_score_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_val_hist = model.history.history['val_f1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_val = [np.mean(item) for item in  f1_score_val_hist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'F1 Score')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loss = f1_scores\n",
    "test_loss = f1_scores_val\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    # Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training F1 score', 'Val F1 score'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is almost the same v.s. our first model using Resnet for extraction only\n",
    "\n",
    "=> model indicates high variability \n",
    "\n",
    "We can:\n",
    "   * Add more data (increase train split ratio, probbaly 9:1 would work for this set)\n",
    "   * Regularization (try more drop outs and strides)\n",
    "   * Or We shall move on with other model structures other than Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
