{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2\n",
    "from PIL import Image \n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH=224\n",
    "IMG_HEIGHT=224\n",
    "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT)\n",
    "BATCH_SIZE = 25\n",
    "IMG_DIR = pathlib.Path('G:\\Github\\standford-dogs\\cropped')\n",
    "TRAIN_DIR = 'G:/Github/standford-dogs/cropped/train'\n",
    "VAL_DIR = 'G:/Github/standford-dogs/cropped/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifiy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Specify the values for all arguments to data_generator_with_aug.\n",
    "data_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                              horizontal_flip = True,\n",
    "                                              width_shift_range = 0.2,\n",
    "                                              height_shift_range = 0.2\n",
    "                                                )\n",
    "            \n",
    "data_generator_no_aug = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18522 images belonging to 120 classes.\n",
      "Found 2058 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator_with_aug.flow_from_directory(\n",
    "                                        directory=TRAIN_DIR,\n",
    "                                        target_size=IMG_DIM,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "validation_generator = data_generator_no_aug.flow_from_directory(\n",
    "                                        directory=VAL_DIR,\n",
    "                                        target_size=IMG_DIM,batch_size=BATCH_SIZE,\n",
    "                                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "resnet = ResNet50(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT,IMG_WIDTH,3),pooling='max')\n",
    "\n",
    "output = resnet.layers[-1].output\n",
    "output = tf.keras.layers.Flatten()(output)\n",
    "resnet = Model(resnet.input, output)\n",
    "\n",
    "res_name = []\n",
    "for layer in resnet.layers:\n",
    "    res_name.append(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv5_block2_1_conv',\n",
       " 'conv5_block2_1_bn',\n",
       " 'conv5_block2_1_relu',\n",
       " 'conv5_block2_2_conv',\n",
       " 'conv5_block2_2_bn',\n",
       " 'conv5_block2_2_relu',\n",
       " 'conv5_block2_3_conv',\n",
       " 'conv5_block2_3_bn',\n",
       " 'conv5_block2_add',\n",
       " 'conv5_block2_out',\n",
       " 'conv5_block3_1_conv',\n",
       " 'conv5_block3_1_bn',\n",
       " 'conv5_block3_1_relu',\n",
       " 'conv5_block3_2_conv',\n",
       " 'conv5_block3_2_bn',\n",
       " 'conv5_block3_2_relu',\n",
       " 'conv5_block3_3_conv',\n",
       " 'conv5_block3_3_bn',\n",
       " 'conv5_block3_add',\n",
       " 'conv5_block3_out',\n",
       " 'max_pool',\n",
       " 'flatten']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_name[-22:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trainable = False\n",
    "for layer in resnet.layers:\n",
    "    if layer.name in res_name[-22:]:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pool (GlobalMaxPooling2D)   (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           max_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 8,931,328\n",
      "Non-trainable params: 14,656,384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Model)                (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               123000    \n",
      "=================================================================\n",
      "Total params: 26,858,488\n",
      "Trainable params: 12,202,104\n",
      "Non-trainable params: 14,656,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "num_classes = 120\n",
    "\n",
    "model = Sequential()\n",
    "model.add(resnet)\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to use resnet50 as feature extraction, hence adding pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8,\n",
    "                                              restore_best_weights=False\n",
    "                                              )\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                   factor=0.2,\n",
    "                                   patience=4,\n",
    "                                   verbose=1,\n",
    "                                   min_delta=5*1e-3,min_lr = 5*1e-7,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics=['accuracy',tfa.metrics.F1Score(num_classes=num_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 741.0 steps, validate for 83.0 steps\n",
      "Epoch 1/100\n",
      "741/741 [==============================] - 269s 363ms/step - loss: 5.5026 - accuracy: 0.0226 - f1_score: 0.0182 - val_loss: 3.9419 - val_accuracy: 0.1550 - val_f1_score: 0.0938\n",
      "Epoch 2/100\n",
      "741/741 [==============================] - 240s 324ms/step - loss: 3.8214 - accuracy: 0.1531 - f1_score: 0.1287 - val_loss: 2.2511 - val_accuracy: 0.4655 - val_f1_score: 0.4120\n",
      "Epoch 3/100\n",
      "741/741 [==============================] - 236s 318ms/step - loss: 2.8320 - accuracy: 0.3041 - f1_score: 0.2864 - val_loss: 1.4948 - val_accuracy: 0.6113 - val_f1_score: 0.5849\n",
      "Epoch 4/100\n",
      "741/741 [==============================] - 235s 317ms/step - loss: 2.2807 - accuracy: 0.4021 - f1_score: 0.3885 - val_loss: 1.2553 - val_accuracy: 0.6438 - val_f1_score: 0.6098\n",
      "Epoch 5/100\n",
      "741/741 [==============================] - 231s 312ms/step - loss: 1.9778 - accuracy: 0.4680 - f1_score: 0.4565 - val_loss: 1.0800 - val_accuracy: 0.6769 - val_f1_score: 0.6544\n",
      "Epoch 6/100\n",
      "741/741 [==============================] - 231s 312ms/step - loss: 1.7191 - accuracy: 0.5224 - f1_score: 0.5111 - val_loss: 1.0004 - val_accuracy: 0.7221 - val_f1_score: 0.7012\n",
      "Epoch 7/100\n",
      "741/741 [==============================] - 232s 313ms/step - loss: 1.5322 - accuracy: 0.5673 - f1_score: 0.5580 - val_loss: 0.9978 - val_accuracy: 0.7162 - val_f1_score: 0.6973\n",
      "Epoch 8/100\n",
      "741/741 [==============================] - 231s 311ms/step - loss: 1.3932 - accuracy: 0.6016 - f1_score: 0.5933 - val_loss: 0.8697 - val_accuracy: 0.7546 - val_f1_score: 0.7363\n",
      "Epoch 9/100\n",
      "741/741 [==============================] - 232s 313ms/step - loss: 1.2849 - accuracy: 0.6309 - f1_score: 0.6236 - val_loss: 0.8749 - val_accuracy: 0.7464 - val_f1_score: 0.7367\n",
      "Epoch 10/100\n",
      "741/741 [==============================] - 232s 313ms/step - loss: 1.1635 - accuracy: 0.6601 - f1_score: 0.6529 - val_loss: 0.8634 - val_accuracy: 0.7517 - val_f1_score: 0.7352\n",
      "Epoch 11/100\n",
      "741/741 [==============================] - 231s 312ms/step - loss: 1.0872 - accuracy: 0.6793 - f1_score: 0.6724 - val_loss: 0.8580 - val_accuracy: 0.7502 - val_f1_score: 0.7390\n",
      "Epoch 12/100\n",
      "741/741 [==============================] - 231s 312ms/step - loss: 0.9999 - accuracy: 0.7022 - f1_score: 0.6962 - val_loss: 0.8791 - val_accuracy: 0.7502 - val_f1_score: 0.7326\n",
      "Epoch 13/100\n",
      "741/741 [==============================] - 231s 312ms/step - loss: 0.9230 - accuracy: 0.7224 - f1_score: 0.7167 - val_loss: 0.8753 - val_accuracy: 0.7614 - val_f1_score: 0.7479\n",
      "Epoch 14/100\n",
      "741/741 [==============================] - 231s 312ms/step - loss: 0.8792 - accuracy: 0.7344 - f1_score: 0.7290 - val_loss: 0.8470 - val_accuracy: 0.7687 - val_f1_score: 0.7560\n",
      "Epoch 15/100\n",
      "741/741 [==============================] - 231s 312ms/step - loss: 0.8064 - accuracy: 0.7526 - f1_score: 0.7468 - val_loss: 0.8163 - val_accuracy: 0.7736 - val_f1_score: 0.7612\n",
      "Epoch 16/100\n",
      "741/741 [==============================] - 231s 312ms/step - loss: 0.7601 - accuracy: 0.7691 - f1_score: 0.7644 - val_loss: 0.8827 - val_accuracy: 0.7527 - val_f1_score: 0.7432\n",
      "Epoch 17/100\n",
      "741/741 [==============================] - 231s 312ms/step - loss: 0.7201 - accuracy: 0.7827 - f1_score: 0.7777 - val_loss: 0.8182 - val_accuracy: 0.7741 - val_f1_score: 0.7603\n",
      "Epoch 18/100\n",
      "741/741 [==============================] - 231s 312ms/step - loss: 0.6793 - accuracy: 0.7912 - f1_score: 0.7866 - val_loss: 0.8907 - val_accuracy: 0.7716 - val_f1_score: 0.7609\n",
      "Epoch 19/100\n",
      "740/741 [============================>.] - ETA: 0s - loss: 0.6434 - accuracy: 0.8022 - f1_score: 0.7983\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "741/741 [==============================] - 231s 312ms/step - loss: 0.6438 - accuracy: 0.8020 - f1_score: 0.7981 - val_loss: 0.8209 - val_accuracy: 0.7823 - val_f1_score: 0.7724\n",
      "Epoch 20/100\n",
      "741/741 [==============================] - 231s 312ms/step - loss: 0.4892 - accuracy: 0.8427 - f1_score: 0.8389 - val_loss: 0.7542 - val_accuracy: 0.8022 - val_f1_score: 0.7921\n",
      "Epoch 21/100\n",
      "741/741 [==============================] - 231s 312ms/step - loss: 0.4335 - accuracy: 0.8609 - f1_score: 0.8577 - val_loss: 0.7419 - val_accuracy: 0.8032 - val_f1_score: 0.7949\n",
      "Epoch 22/100\n",
      "741/741 [==============================] - 231s 312ms/step - loss: 0.3846 - accuracy: 0.8715 - f1_score: 0.8682 - val_loss: 0.7524 - val_accuracy: 0.8022 - val_f1_score: 0.7943\n",
      "Epoch 23/100\n",
      "741/741 [==============================] - 231s 312ms/step - loss: 0.3754 - accuracy: 0.8792 - f1_score: 0.8760 - val_loss: 0.7257 - val_accuracy: 0.8061 - val_f1_score: 0.8006\n",
      "Epoch 24/100\n",
      "741/741 [==============================] - 231s 312ms/step - loss: 0.3548 - accuracy: 0.8823 - f1_score: 0.8793 - val_loss: 0.7552 - val_accuracy: 0.8022 - val_f1_score: 0.7950\n",
      "Epoch 25/100\n",
      "741/741 [==============================] - 231s 311ms/step - loss: 0.3366 - accuracy: 0.8907 - f1_score: 0.8876 - val_loss: 0.7575 - val_accuracy: 0.7979 - val_f1_score: 0.7885\n",
      "Epoch 26/100\n",
      "741/741 [==============================] - 232s 313ms/step - loss: 0.3296 - accuracy: 0.8923 - f1_score: 0.8895 - val_loss: 0.7703 - val_accuracy: 0.8017 - val_f1_score: 0.7906\n",
      "Epoch 27/100\n",
      "740/741 [============================>.] - ETA: 0s - loss: 0.3150 - accuracy: 0.8949 - f1_score: 0.8921\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "741/741 [==============================] - 231s 311ms/step - loss: 0.3149 - accuracy: 0.8949 - f1_score: 0.8922 - val_loss: 0.7719 - val_accuracy: 0.8017 - val_f1_score: 0.7930\n",
      "Epoch 28/100\n",
      "741/741 [==============================] - 230s 311ms/step - loss: 0.2969 - accuracy: 0.8996 - f1_score: 0.8970 - val_loss: 0.7678 - val_accuracy: 0.8032 - val_f1_score: 0.7941\n",
      "Epoch 29/100\n",
      "741/741 [==============================] - 231s 311ms/step - loss: 0.2807 - accuracy: 0.9065 - f1_score: 0.9041 - val_loss: 0.7698 - val_accuracy: 0.8017 - val_f1_score: 0.7932\n",
      "Epoch 30/100\n",
      "741/741 [==============================] - 231s 311ms/step - loss: 0.2745 - accuracy: 0.9076 - f1_score: 0.9050 - val_loss: 0.7710 - val_accuracy: 0.8017 - val_f1_score: 0.7938\n",
      "Epoch 31/100\n",
      "740/741 [============================>.] - ETA: 0s - loss: 0.2720 - accuracy: 0.9079 - f1_score: 0.9057\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "741/741 [==============================] - 231s 311ms/step - loss: 0.2725 - accuracy: 0.9078 - f1_score: 0.9056 - val_loss: 0.7682 - val_accuracy: 0.8047 - val_f1_score: 0.7959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fb674ddbe0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,\n",
    "          steps_per_epoch=np.ceil(float(18522) / float(BATCH_SIZE)),\n",
    "          epochs = 100,callbacks=[early_stop,reduce_lr],\n",
    "          validation_steps=np.ceil(float(2058) / float(BATCH_SIZE)),\n",
    "          validation_data = validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagnostic_plot(model,name):\n",
    "    training_loss = model.history.history[name]\n",
    "    test_loss = model.history.history[f'val_{name}']\n",
    "\n",
    "    # Create count of the number of epochs\n",
    "    epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    # Visualize loss history\n",
    "    plt.plot(epoch_count, training_loss, 'r--')\n",
    "    plt.plot(epoch_count, test_loss, 'b-')\n",
    "    plt.legend([f'Training {name}', f'Val {name}'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_diagnostic_plot(model,'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_diagnostic_plot(model,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Zhiqing\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: G:/Github/Dogs_breed_classification/resnet50_5/assets\n"
     ]
    }
   ],
   "source": [
    "save_path = 'G:/Github/Dogs_breed_classification/resnet50_5/'\n",
    "tf.keras.models.save_model(model,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_history = model.history.history['f1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = [np.mean(item) for item in  f1_score_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_val_hist = model.history.history['val_f1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_val = [np.mean(item) for item in  f1_score_val_hist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'F1 Score')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loss = f1_scores\n",
    "test_loss = f1_scores_val\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    # Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training F1 score', 'Val F1 score'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not improve much\n",
    "\n",
    "Guess we need to move on to another model\n",
    "too bad it does not achieve the best as Resnet50 should (~ 90%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
